{"task_id": "CUDA/0", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nImplement a function called `launch` that launches a kernel function named `kernel` with the provided grid and block dimensions using triple chevrons. The x,y,z grid sizes and block sizes will be provided as parameters\nto the `launch` function. Assume that the `kernel` function is already defined. \n\nThe signature of the `kernel` function is\n```cuda\n__global__ void kernel(int *output, const int *input) \n```\n\nThe function signature is \n```cuda\nvoid launch(int gridSizeX, int blockSizeX, int gridSizeY = 1, int blockSizeY = 1, int gridSizeZ = 1, int blockSizeZ = 1)\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cuda.h>\n#include \"cuda_runtime.h\"\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/1", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nImplement a function called `launch` that launches a kernel function named `kernel` with the provided grid and block dimensions using triple chevrons and also allocates dynamic shared memory. The x,y,z grid sizes and block sizes will be provided as parameters\nto the `launch` function. Assume that the `kernel` function is already defined. \n\nThe signature of the `kernel` function is\n```cuda\n__global__ void kernel(int *output, const int *input) \n```\n\nThe function signature is \n```cuda\nvoid launch(int gridSizeX, int blockSizeX, int gridSizeY = 1, int blockSizeY = 1, int gridSizeZ = 1, int blockSizeZ = 1)\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cuda.h>\n#include \"cuda_runtime.h\"\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/2", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nImplement a function called `launch` that launches a kernel function named `kernel` with the provided grid and block dimensions using triple chevrons, allocates dynamic shared memory and also uses cuda streams. The x,y,z grid sizes and block sizes will be provided as parameters\nto the `launch` function. Assume that the `kernel` function is already defined. \n\nThe signature of the `kernel` function is\n```cuda\n__global__ void kernel(int *output, const int *input) \n```\n\nThe function signature is \n```cuda\nvoid launch(int gridSizeX, int blockSizeX, int gridSizeY = 1, int blockSizeY = 1, int gridSizeZ = 1, int blockSizeZ = 1)\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cuda.h>\n#include \"cuda_runtime.h\"\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/3", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nImplement a function called `launch` that launches a kernel function named `kernel` without using triple chevrons. The x,y,z grid and dimensions will be provided as parameters\nto the `launch` function. Assume that the `kernel` function is already defined. \n\nThe signature of the `kernel` function is\n```cuda\n__global__ void kernel(int *output, const int *input) \n```\n\nThe function signature is \n```cuda\nvoid launch(int gridSizeX, int blockSizeX, int gridSizeY = 1, int blockSizeY = 1, int gridSizeZ = 1, int blockSizeZ = 1)\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cuda.h>\n#include \"cuda_runtime.h\"\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/4", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nImplement a function called `launch` that launches a kernel function named `kernel` with thread block clusters and wihout using triple chevrons. The x,y,z grid and dimensions will be provided as parameters\nto the `launch` function. Assume that the `kernel` function is already defined. \n\nThe signature of the `kernel` function is\n```cuda\n__global__ void kernel(int *output, const int *input) \n```\n\nThe function signature is \n```cuda\nvoid launch(int gridSizeX, int blockSizeX, int gridSizeY = 1, int blockSizeY = 1, int gridSizeZ = 1, int blockSizeZ = 1)\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cuda.h>\n#include \"cuda_runtime.h\"\n#include <iostream>\n#include <fstream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/5", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nImplement a kernel called `kernel` that has launch bounds set to ensure optimal execution efficiency by limiting the maximum number of threads per block to MAX_THREADS_PER_BLOCK and the minimum number of blocks per multiprocessor to MIN_BLOCKS_PER_MULTIPROCESSOR. \nThis ensures that the kernel runs efficiently on the GPU by maximizing occupancy while maintaining sufficient resources per block.\n\nAssume that the following constants are defined:\n- `MAX_THREADS_PER_BLOCK`: the maximum number of threads that can be assigned to a block\n- `MIN_BLOCKS_PER_MULTIPROCESSOR`: the minimum number of blocks that can be to multiprocessor core.\n\nImplement the kernel function that takes an int* and const int* as parameters.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cuda.h>\n#include \"cuda_runtime.h\"\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/6", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nImplement a kernel called `kernel` that has launch bounds set to ensure optimal execution efficiency by limiting the maximum number of threads per block to MAX_THREADS_PER_BLOCK, the minimum number of blocks per multiprocessor to MIN_BLOCKS_PER_MULTIPROCESSOR and the maximum number of thread blocks in a cluster to MAX_BLOCKS_PER_CLUSTER. \n\nAssume that the following constants are defined:\n- `MAX_THREADS_PER_BLOCK`: the maximum number of threads that can be assigned to a block\n- `MIN_BLOCKS_PER_MULTIPROCESSOR`: the minimum number of blocks that can be to multiprocessor core.\n- `MAX_BLOCKS_PER_CLUSTER`:  the maximum number of thread blocks per cluster\n\nImplement the kernel function that takes an int* and const int* as parameters.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cuda.h>\n#include \"cuda_runtime.h\"\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/7", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nImplement a CUDA kernel called conv2d_kernel that performs a 2-dimensional convolution on the input\nfloat matrix and populates the output matrix with these values. Assume that the input matrix is in\nrow-major order and ensure that the output matrix is populated in row-major order as well. You can\nassume that there is no padding in this convolution and the stride is 1.\n\nThe signature of the function is\n```cuda\n__global__ void conv2d_kernel(float *input, float *output, unsigned int W, unsigned int H, unsigned\nint oW, unsigned int oH)\n```\nwhere W, H are the input width and heights and oW, oH are the output width and height\n\nAssume that the following constants are defined:\n- `MASK_RADIUS`:  the mask radius is the distance from the center of the convolution mask or kernel\nto its outermost elements.\n- `MASK_DIM`: The mask dimension (or kernel dimension) refers to the spatial dimensions or the shape\nof the convolution mask. Defined as 2 * MASK_RADIUS + 1\n\nAdditionally, assume that the mask is stored in constant memory as a 2d array named `mask_c`.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cassert>\n#include <chrono>\n#include <iostream>\n#include <random>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/8", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nImplement a CUDA function called `run_cuda_graph` that sets up and executes a CUDA graph for\nprocessing an image represented as a 1D array. The function signature is `void run_cuda_graph(float*\nd_img, float* h_result, int width, int height)`. In this function, you will create a CUDA graph to\napply several image processing steps: edge detection, normalization, blurring, combining results,\nand a final transformation. You will use the following kernels in your graph:\n\n- `apply_edge_detection(float* img, float* result, int width, int height)`\n- `normalize_image(float* img, int width, int height)`\n- `apply_blur_filter(float* img, float* result, int width, int height)`\n- `combine_filtered_results(float* edge_result, float* blur_result, float* combined_result, int\nwidth, int height)`\n- `final_transformation(float* img, int width, int height)`\n\nAllocate the necessary device memory and configure the graph nodes with appropriate parameters.\nFirst, apply the edge detection filter to the input image and normalize the resulting image values.\nThen, apply a blur filter to the normalized image. Combine the results of the edge detection and the\nblur filters. Perform a final transformation on the combined result.\n\nUse a block size of 256 threads and ensure the graph executes 100 times. After executing the graph,\ncopy the final result back to the host.\n\nThe signature of the function is:\n```cuda\nvoid run_cuda_graph(float* d_img, float* h_result, int width, int height)\n```\n\nYou should assume the kernels are already defined.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cuda_runtime.h>\n#include <cassert>\n#include <cstdlib>\n#include <ctime>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/9", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA function called `dot_product` that calculates the dot product of two vectors using\ndynamic shared memory. The function should efficiently handle cases where the size of the vectors\nmay be larger than the total number of available threads.\n\nThe signature of the function is:\n```cuda\n__global__ void dot_product(const float *A, const float *B, float *result, int ds)\n```\n\nImplement the body of the function. Use dynamic shared memory to store the partial sums within each\nblock.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <assert.h>\n#include <stdio.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/10", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA function called `gpuRecursiveReduce` that performs recursive reduction on an input\narray using dynamic parallelism and dynamic shared memory.\n\nThe signature of the function is:\n```cuda\n__global__ void gpuRecursiveReduce(int *g_idata, int *g_odata, unsigned int isize)\n```\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <assert.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/11", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nImplement a CUDA kernel function called `histogram` that efficiently calculates the histogram of a large input array of non-negative integers. The number of histogram bins is determined by the `num_bins` parameter. Use dynamic shared memory for storing the block-level histogram bins. The function should be optimized for performance and handle input arrays that are larger than the number of threads in a block.\n\nThe signature of the function is:\n```cuda\n__global__ void histogram(int *input, int *bins, int size, int num_bins)\n```\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cstdio>\n#include <cassert>\n#include <cstdlib>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/12", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nImplement a CUDA kernel function called `histogram_2d` to calculate the 2D histogram of an input\narray of non-negative integer pairs. Each pair represents coordinates in a 2D space. The histogram\nbins, determined by `num_bins_x` and `num_bins_y`, should be stored in global memory as a 1D array\nin row-major order.\n\nThe input array `input` is a 1D array of size `2 * size`, where each pair of consecutive elements\nrepresents the x and y coordinates of a point. Use dynamic shared memory for the histogram bins\nwithin each block.\n\nThe function signature is:\n```cuda\n__global__ void histogram_2d(int *input, int *bins, int size, int num_bins_x, int num_bins_y)\n```\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cassert>\n#include <cstdio>\n#include <cstdlib>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/13", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA function called `inc` that increments a large array on the GPU. The function should be\nable to handle arrays that are larger than the total number of threads launched in the grid.\n\nThe signature of the function is:\n```cuda\n__global__ void inc(int *array, size_t n)\n```\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cassert>\n#include <cstdio>\n#include <cstdlib>\n#include <cstring>\n#include <ctime>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/14", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA function called `mmul` that performs matrix multiplication of two square matrices using\nstatically allocated shared memory. Assume that the block size is already defined as a constant\n`block_size`. Use it appropriately in your function.\n\nThe signature of the function is:\n```cuda\n__global__ void mmul(const float *A, const float *B, float *C, int ds)\n```\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <assert.h>\n#include <stdio.h>\n#include <time.h>\n#include <cstdlib>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/15", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite CUDA functions to perform parallel reductions using specific partitioning strategies:\n\n1. A device function called `reduce`, which uses a cooperative group to perform a reduction on\nintegers stored in dynamic shared memory. This function should return the reduced result from shared\nmemory.\n2. Multiple kernel functions demonstrating different partitioning strategies:\n   - `block_reduce_kernel` uses the entire block as a single group.\n   - `tile32_reduce_kernel` uses tiled partitioning with a tile size of 32.\n\nThe following headers are already defined and should not be included in the response:\n```\n#include <cooperative_groups.h>\nusing namespace cooperative_groups;\n```\n\nImplement the functions in the following order using the provided signatures:\n```cuda\n__device__ int reduce(thread_group g, int *x, int val);\n__global__ void block_reduce_kernel(int *data, int *result, int size);\n__global__ void tile32_reduce_kernel(int *data, int *result, int size);\n```\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <assert.h>\n#include <cooperative_groups.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/16", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA function called `performComplexConcurrentOperations` that takes three input arrays and\nan output array, performs a series of operations using CUDA kernels, and returns the processed data\nback to the host. The CUDA kernel functions you need to apply are defined as follows:\n\n```cuda\n__global__ void kernelSquare(int *data, int size) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < size) {\n        data[i] = data[i] * data[i];\n    }\n}\n\n__global__ void kernelIncrement(int *data, int size) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < size) {\n        data[i] += 1;\n    }\n}\n\n__global__ void kernelDouble(int *data, int size) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < size) {\n        data[i] *= 2;\n    }\n}\n\n__global__ void kernelAdd(int *result, const int *a, const int *b, int size) {\n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < size) {\n        result[i] = a[i] + b[i];\n    }\n}\n```\n\nIn the `performComplexConcurrentOperations` function, use CUDA streams to perform the following\noperations efficiently: compute the intermediate arrays \\( X' = X^2 \\), \\( Y' = Y + 1 \\), and \\( Z'\n= 2Z \\); then calculate \\( A = X' + Y' \\) and \\( B = Y + Z' \\); and finally compute the result as \\(\n\\text{result} = (A + B)^2 \\). Ensure the use of appropriate concurrency mechanisms to optimize\nperformance.\n\nThe signature of the `performComplexConcurrentOperations` function is:\n```cuda\nvoid performComplexConcurrentOperations(int *result, const int *arrayX, const int *arrayY, const int\n*arrayZ, int size)\n```\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cassert>\n#include <cstdlib>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/17", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA function called `reduce` that performs a max-finding reduction to find the maximum\nvalue in an array using a parallel-sweep-reduction technique. Assume that `BLOCK_SIZE` is defined as\na constant. Use `BLOCK_SIZE` appropriately in your function.\n\nThe signature of the function is:\n```cuda\n__global__ void reduce(float *gdata, float *out, size_t n)\n```\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <assert.h>\n#include <float.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/18", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA function called `row_sums` that performs a simple matrix row sum.\n\nThe signature of the function is:\n```cuda\n__global__ void row_sums(const float *A, float *sums, size_t ds)\n```\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <assert.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n#include <cmath>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/19", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA function called `process_data_on_gpu` that takes in a large dataset of floating-point\nvalues, applies a special operation to each element using a separate CUDA kernel, and returns the\nprocessed data back to the host. The CUDA kernel function you need to apply is defined as follows:\n\n```\n__global__ void apply_special_operation(float *data, size_t n) {\nsize_t idx = threadIdx.x + blockDim.x * blockIdx.x;\nif (idx < n) {\n    if (data[idx] > 0 && data[idx] < 10) {\n        data[idx] *= 2;\n    } else if (data[idx] >= 10) {\n        data[idx] -= 10;\n    } else {\n        data[idx] = 0;\n    }\n}\n```\n\nIn the `process_data_on_gpu` function, allocate memory for the input and output data on the GPU,\ntransfer the input data from the host to the GPU, launch the kernel aove with an appropriate number\nof blocks and threads to process the entire dataset, transfer the output data back to the host, and\nfree the allocated memory on the GPU.\n\nThe signature of the `process_data_on_gpu` function is:\n```cuda\nvoid process_data_on_gpu(float *h_input, float *h_output, size_t n)\n```\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <assert.h>\n#include <cuda_runtime.h>\n#include <math.h>\n#include <stdio.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/20", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel function called `stencil_1d` that performs a 1D stencil operation on a large 1D\narray. The stencil operation should calculate the sum of each element and its neighboring elements\nwithin a specified radius. The function should handle array sizes larger than the number of threads\nin a block and utilize statical shared memory for optimization.\n\nAssume that the following constants are defined:\n- `BLOCK_SIZE`: The number of threads per block\n- `RADIUS`: The radius of the stencil\n\nThe signature of the function is:\n```cuda\n__global__ void stencil_1d(int *in, int *out)\n```\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cassert>\n#include <cstdio>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/21", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nImplement a CUDA kernel called stencil3d_kernel that performs a 3d stencil operation on the input\nfloat matrix and populates the output matrix with these values. The stencil operation should\ncalculate the sum of each element and its neighboring elements within a specified radius weighted by\na two values (C0) and (C1). C0 indicates how much a The function should handle array sizes larger\nthan the number of threads in a block and utilize statical shared memory and thread coarsening for\noptimization.\n\nAssume that the following constants are defined:\n- `BLOCK_DIM`: The number of threads per block\n- `C0`: the weight of the element itself\n- `C1`: the weight of the neighbouring elements\n- `IN_TILE_DIM`: the tile size on the input array\n- `OUT_TILE_DIM`: the tile size on the output array\n\n\nThe signature of the function is:\n```cuda\n__global__ void stencil3d_kernel(float *input, float *output, unsigned int N)\n```\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cassert>\n#include <cstdlib>\n#include <ctime>\n#include <iostream>\n#include <random>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/22", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA function called `transpose` that performs matrix transpose on a non-square matrix using\nstatically allocated shared memory. The input matrix is stored in row-major order, and the output\nmatrix should also be stored in row-major order.\n\nAssume that the following constant is defined:\n- `BLOCK_SIZE`: The size of the square thread block\n\nThe matrix dimensions, `width` and `height`, can be larger than `BLOCK_SIZE`. The function should\nhandle non-square matrices efficiently.\n\nThe signature of the function is:\n```cuda\n__global__ void transpose(const float *input, float *output, int width, int height)\n```\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <assert.h>\n#include <stdio.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/23", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nImplement a function called `transposeSquareMatrixManaged` that uses CUDA's Unified Memory to\ntranspose a square matrix. Below is the CUDA kernel `transposeSquareMatrixKernel` that performs the\nmatrix transposition which you can use in your function.\n\n```cuda\n__global__ void transposeSquareMatrixKernel(float* out, const float* in, int N) {\n    extern __shared__ float tile[];\n    int x = blockIdx.x * blockDim.x + threadIdx.x;\n    int y = blockIdx.y * blockDim.y + threadIdx.y;\n    int width = blockDim.x;\n\n    if (x < N && y < N) {\n        tile[threadIdx.y * width + threadIdx.x] = in[y * N + x];\n    }\n    __syncthreads();\n\n    x = blockIdx.y * blockDim.y + threadIdx.x; // transpose block offset\n    y = blockIdx.x * blockDim.x + threadIdx.y;\n\n    if (x < N && y < N) {\n        out[y * N + x] = tile[threadIdx.x * width + threadIdx.y];\n    }\n}\n```\n\nUse a block size of \\( 16 \\times 16 \\) for the CUDA kernel launch.\n\nThe signature of the function is:\n```cuda\nvoid transposeSquareMatrixManaged(float* h_in, float* h_out, int N)\n```\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cuda_runtime.h>\n#include <cassert>\n#include <cstdlib>\n#include <ctime>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/24", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA function called `vadd` that adds two vectors, the parameters are A and B.\n\nThe signature of the function is:\n```cuda\n__global__ void vadd(const float *A, const float *B, float *C, int ds)\n```\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <assert.h>\n#include <cuda.h>\n#include <math.h>\n#include <stdio.h>\n#include <stdlib.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/25", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite 2 device level functions called `reduce_warp` and `reduce_threadblock` to reduce data spread across threads in a thread block.\nThis includes performing a reduction operation within a warp and then across the entire thread block using shared memory. Use warp-level primitives to achieve this task.\nThe `reduce_warp` function should support the following warp sizes: 2, 4, 8, 16, and 32.\n\nA CUDA kernel will call these functions. The definition for the kernel `kernel` is \n```cuda\n__global__ void kernel(float *pOut, const float *pIn) {\n    /// this kernel assumes the threadblock size is 1024\n    extern __shared__ char smem_[];\n    float *smem = reinterpret_cast<float *>(smem_);\n    int tx = threadIdx.x;\n    float v = pIn[tx];\n    v = reduce_warp(v);\n    v = reduce_threadblock(v, smem);\n    if (threadIdx.x == 0) {\n        pOut[0] = v;\n    }\n```\n\nThe functions signatures are \n```cuda\ntemplate <int WARP_SIZE> __device__ float reduce_warp(float v)\ntemplate <int WARP_SIZE> __device__ float reduce_threadblock(float v, float *smem)\n```\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cuda.h>\n#include \"cuda_runtime.h\"\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/26", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite 2 device level functions called `reduce_warp` and `reduce_threadblock` to minimize data spread across threads within a warp to enhance data locality and performance. \nUse warp-level primitives to achieve this task.  \nA CUDA kernel will call these functions. The definition of the kernel is \n\n```cuda\n__global__ void kernel(float *pOut, const float *pIn) {\n    extern __shared__ char smem_[];\n    float *smem = reinterpret_cast<float *>(smem_);\n    int tx = threadIdx.x;\n    float v = pIn[tx];\n    v = reduce_warp(v);\n    v = reduce_threadblock(v, smem);\n    if (threadIdx.x == 0) {\n        pOut[0] = v;\n    }\n}\n```\n\nThe signature of the functions must be \n```cuda\n__device__ float reduce_warp(float v)\n__device__ float reduce_threadblock(float v, float *smem)\n```\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cuda.h>\n#include \"cuda_runtime.h\"\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/27", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nImplement 2 functions `reduce_warp` and `reduce_threadblock` that perform partial sum reduction across a thread block. \nThe reduction should minimize data spread across threads using warp-level and thread block-level reduction techniques\nWrite 2 device-level functions to handle the warp-wide reduction and thread block-wide reduction, ensuring that the final sum is correctly computed across all thread blocks.\n\nThe definition for the kernel is \n```cuda\n__global__ void kernel_partialsum(float *pOut, const float *pIn, int N) {\n    extern __shared__ char smem_[];\n    float *smem = reinterpret_cast<float *>(smem_);\n    int index = threadIdx.x + blockIdx.x * blockDim.x;\n\n    float v = 0.0f;\n\n    if (index < N) {\n        v = pIn[index];\n        v = reduce_warp(v);\n        v = reduce_threadblock(v, smem);\n        if (threadIdx.x == 0) {\n            pOut[blockIdx.x] = v;\n        }\n    }\n}\n```\n\nThe functions signatures are \n```cuda\n__device__ float reduce_warp(float v)\n__device__ float reduce_threadblock(float v, float *smem)\n```\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cuda.h>\n#include \"cuda_runtime.h\"\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/28", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a device level function called `reduce_warp` to minimize data spread across threads in a warp.\nImplement a summation of floating point data across threads in a warp using shuffle instructions in CUDA.\nThe function should support the following warp sizes: 2, 4, 8, 16, and 32. \n\nA CUDA kernel will call this function `reduce_warp`. The definition of the kernel is \n```cuda\n__global__ void kernel(float *pOut, const float *pIn) {\n    int tx  = threadIdx.x;\n    float v = pIn[tx];\n    v = reduce_warp(v);\n    if (threadIdx.x == 0) {\n        pOut[0] = v;\n    }\n}\n```\n\nThe function signature is \n```cuda\ntemplate <int WARP_SIZE> __device__ float reduce_warp(float);\n```\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cuda.h>\n#include \"cuda_runtime.h\"\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/29", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a device level function called `reduce_warp` to minimize data spread across threads in a warp.\nImplement a summation of floating point data across threads in a warp using shuffle instructions in CUDA. \n\nA CUDA kernel will call this function `reduce_warp`. The definition of the kernel is \n```cuda\n__global__ void kernel(float *pOut, const float *pIn) {\n    int tx  = threadIdx.x;\n    float v = pIn[tx];\n    v = reduce_warp(v);\n    if (threadIdx.x == 0) {\n        pOut[0] = v;\n    }\n}\n```\n\nThe function signature is \n```cuda\n__device__ float reduce_warp(float v)\n```\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cuda.h>\n#include \"cuda_runtime.h\"\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/30", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite CUDA functions to perform grid synchronization using cooperative groups:\n\n1. A kernel function called `sync_kernel` that uses cooperative groups to synchronize grid. \n   This kernel should invoke `pre_sync()` before the grid sync and `post_sync()` after the grid sync.\n   The beginning of the kernel should look like:\n   ```cuda\n   template <class PreSync, class PostSync>\n   __global__ void sync_kernel(PreSync pre_sync, PostSync post_sync) {\n      pre_sync();\n   ```\n   followed by the cooperative groups grid synchronization, followed by `post_sync()` invocation.\n2. A host function called `launch` that launches the `sync_kernel` using `cudaLaunchCooperativeKernel`.\n\nThe following headers are already defined and should not be included in the response:\n```cuda\n#include <cooperative_groups.h>\n```\n\nImplement the functions in the following order using the provided signatures:\n```cuda\ntemplate <class PreSync, class PostSync>\n__global__ void sync_kernel(PreSync pre_sync, PostSync post_sync);\n\ntemplate <class PreSync, class PostSync>\nvoid launch(int num_blocks, int block_size, PreSync pre_sync, PostSync post_sync);\n```\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cooperative_groups.h>\n#include <cuda_runtime_api.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/31", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `void add(int num_items, const int *in, int *out)` that adds `num_items` elements on GPU using CUB library. \nThe resulting sum should be stored in `out`.  \nThe following headers are already defined and should not be included in the response:\n```cuda\n#include <cub/device/device_reduce.cuh>\n```\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n#include <thrust/device_vector.h>\n#include <cub/device/device_reduce.cuh>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/32", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `void scan(int num_items, const int *in, int *out)` that computes exclusive prefix sum of `num_items` elements on GPU using CUB library. \nThe resulting should be stored in `out`.  \nThe following headers are already defined and should not be included in the response:\n```cuda\n#include <cub/device/device_scan.cuh>\n```\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n#include <thrust/device_vector.h>\n#include <cub/device/device_scan.cuh>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/33", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `void sort(int num_items, const int *in, int *out)` that sorts `num_items` elements on GPU using radix sort from CUB library. \nThe resulting should be stored in `out`.  \nThe following headers are already defined and should not be included in the response:\n```cuda\n#include <cub/device/device_radix_sort.cuh>\n```\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n#include <thrust/device_vector.h>\n#include <cub/device/device_radix_sort.cuh>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/34", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel where each thread uses cuda::atomic_ref from libcu++ to increment a value in a device memory by one. \nUse device scope for atomic increment. The kernel should have the following signature:\n```cuda\n__global__ void kernel(int *ptr);\n```\n\nThe following headers are already defined and should not be included in the response:\n```cuda\n#include <cuda/atomic>\n```\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cuda/atomic>\n#include <cuda_runtime_api.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/35", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `thrust::device_vector<int> scan(const thrust::device_vector<int>& vec)` that\ncomputes exclusive prefix sum of the input vector on GPU using thrust algorithm.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/execution_policy.h>\n#include <thrust/scan.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/36", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `float sum(const thrust::device_vector<float>& vec)` that adds all elements of a\nvector on GPU using thrust algorithm.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/reduce.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/37", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `thrust::device_vector<int> sort(const thrust::device_vector<int>& vec)` that sorts\nthe input vector on GPU using thrust algorithm.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/execution_policy.h>\n#include <thrust/sort.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/38", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `thrust::device_vector<float> vadd(const thrust::device_vector<float>& x, const\nthrust::device_vector<float>& y)` that adds two vectors on GPU.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/transform.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/39", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `thrust::device_vector<int>::iterator find(thrust::device_vector<int>&\nvec, int target)` that finds the first occurrence of the target value in the input vector.\n\nDo not include any code outside the function. Wrap the completed function code, including the\nprovided signature, inside a ```cuda markdown code block.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/find.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/40", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `void inclusive_add(thrust::device_vector<int>& x)` that\ncomputes an inclusive prefix sum in all the values of the array. It should do it inplace\nand the resulting array should stay on the device.\nDo not include any code outside the function. Wrap the completed function\ncode, including the provided signature, inside a ```cuda markdown code block.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/scan.h>\n#include <thrust/transform.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/41", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `int partitionVector(thrust::device_vector<int>& vec)` that takes a device vector\nas input and reorders the vector elements. The first elements should be less than 10 followed by the\nitems who are greater. The operation should be inplace and the function should return the index of\nthe first element that does not satisfy the condition.\n\nDo not include any code outside the function. Wrap the completed function code, including the\nprovided signature, inside a ```cuda markdown code block.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/partition.h>\n#include <thrust/sort.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/42", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `int partitionVector(thrust::device_vector<int>& vec)` that takes a device vector\nas input and reorders the vector elements. The function should preserve relative order of the input.\nThe first elements should be less than 10 followed by the elements who are greater. The operation\nshould be inplace and the function should return the index of the first element that does not\nsatisfy the condition.\n\nDo not include any code outside the function. Wrap the completed function code, including the\nprovided signature, inside a ```cuda markdown code block.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/partition.h>\n#include <thrust/sort.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/43", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `void copy(const thrust::device_vector<float>& src,\nthrust::device_vector<float>& dst)` that copies half the elements of a src\nvector in GPU to a dst vector in GPU.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/copy.h>\n#include <thrust/device_vector.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/44", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `void fill_vector_increasingly(thrust::device_vector<int>& vec)` that fills a\nvector with sequentially increasing numbers starting from 0 to `.size() - 1` using thrust\nalgorithm.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/execution_policy.h>\n#include <thrust/sequence.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/45", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `thrust::device_vector<int> combine_ranges(thrust::device_vector<int> const& vec1,\nthrust::device_vector<int> const& vec2)` that combines two sorted vectors into a single sorted\nvector in the GPU using a thrust algorithm.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/execution_policy.h>\n#include <thrust/merge.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/46", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `thrust::device_vector<int> redistribute_elements(thrust::device_vector<int> const&\nvec, thrust::device_vector<int> const& map)` that takes an input vector and a map vector (of equal\nsize) that holds indices. It returns a new vector where each element from source is redistributed\naccording to the index pointed by the corresponding element in the map vector using a thrust\nalgorithm.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/scatter.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/47", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `thrust::device_vector<int> remap_elements(thrust::device_vector<int> const& vec,\nthrust::device_vector<int> const& map)` that takes an input vector and a map vector and returns a\nnew vector (equal size to map.size()) where each element is being picked from the source according to the index\nindicated by map using a thrust algorithm.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/gather.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/48", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `std::size_t find_partition_barrier(thrust::device_vector<int> const& vec)` that\ntakes an already partitioned device vector where its first partition is even numbers and its second\npartition is odd numbers as input and finds the index at which the partition takes place. Use a\nsingle thrust algorithm.\n\nDo not include any code outside the function. Wrap the completed function code, including the\nprovided signature, inside a ```cuda markdown code block.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/partition.h>\n#include <thrust/sort.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/49", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `void shift_by_5(thrust::device_vector<int>::iterator& it)` that takes a device\nvector iterator and shifts it ahead it by 5 elements using one thrust algorithm.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/advance.h>\n#include <thrust/device_vector.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/50", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `void flip_values(thrust::device_vector<int> &vec1, thrust::device_vector<int>\n&vec2)` that accepts two device vectors and exchanges their values with each other using a thrust\nalgorithm.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/swap.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/51", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `\nthrust::device_vector<char> find_the_word(\n  thrust::device_vector<char> const& chunk1,\n  thrust::device_vector<int> const& keys1,\n  thrust::device_vector<char> const& chunk2,\n  thrust::device_vector<int> const& keys2)` that merges the two input chunk vectors that hold\ncharacters according to their corresponding key vectors in the GPU. You are required to use only\none thrust algorithm. The resulting device vector should hold all the merged characters from chunk1,\nchunk2 in order according to keys1, keys2 to form the final word.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/execution_policy.h>\n#include <thrust/host_vector.h>\n#include <thrust/merge.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/52", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `thrust::device_vector<float> local_prefix_maxima(thrust::device_vector<float>\nconst &vec, thrust::device_vector<int> const &keys);` that given an input vector and a keys vector\ncalculates the prefix maximum for each group of input elements that correspond to the same keys\nusing one thrust algorithm. Returns a new vector with equal size to the input vector that holds\nprefix maximum values.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/host_vector.h>\n#include <thrust/scan.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/53", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `void remove_consecutive_duplicates(thrust::device_vector<int> &vec)` that removes\nduplicate elements from the input vector on GPU using thrust algorithm.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/execution_policy.h>\n#include <thrust/unique.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/54", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `thrust::device_vector<int>\nlocal_prefix_exclusive_sum(thrust::device_vector<int> const &vec, thrust::device_vector<int>\nconst &keys);` that given an input vector and a keys vector calculates the exclusive prefix sum\nfor each group of input elements that correspond to the same keys. Use only one thrust algorithm.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/host_vector.h>\n#include <thrust/scan.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/55", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `int negate_and_add(const thrust::device_vector<int> &vec)` that negates all\nelements of the input vector and then adds them all together on GPU using one thrust algorithm.\nRetiurn the sum.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/transform_reduce.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/56", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `void replace_twos(thrust::device_vector<int>& vec)` that replaces the elements of\na vector with the value 2 with the value -2 using a Thrust algorithm.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/replace.h>\n#include <cstddef>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/57", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `void copy_evens(const thrust::device_vector<int>& src,\nthrust::device_vector<int>& dst)` that copies the even integers of a src\nvector in GPU to a dst vector in GPU using a Thrust algorithm.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/copy.h>\n#include <thrust/device_vector.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/58", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `bool has_negatives(thrust::device_vector<int> const& vec)` that checks whether\nthere are any negatives in the input vector using a thrust algorithm. Do not use `thrust::all_of`.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/logical.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/59", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `thrust::device_vector<int> only_common(thrust::device_vector<int> const& vec1,\nthrust::device_vector<int> const& vec2)` that combines only the common elements of two input sorted\nvectors into a single sorted vector and returns it using one thrust algorithm.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/set_operations.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/60", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `thrust::pair<float, float> find_extrema(const thrust::device_vector<float>\n&vec)` that finds and returns the maximum and the minimum values (as a pair) of the input vector\nusing a thrust algorithm.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/extrema.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/61", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `thrust::device_vector<int> combine(thrust::device_vector<int> const& vec1,\nthrust::device_vector<int> const& vec2)` that combines every element of two input sorted vectors\ninto a single sorted vector and returns it using one thrust algorithm. If an element in exists\nin both inputs it shouldn't be duplicated.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/set_operations.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/62", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `bool no_positives(thrust::device_vector<int> const& vec)` that checks whether\nno values in a vector are positive using the proper logical thrust algorithm. Don't use\nthrust::all_of, thrust::any_of, thrust::find/(_if) or thrust::count/(_if).\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/logical.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/63", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `thrust::device_vector<int> reduce_chunks(thrust::device_vector<int>& vec,\nthrust::device_vector<int> const& keys)` that adds all elements of the input vector vec that have\nthe same corresponding key value in the keys vector on GPU using one thrust algorithm. It should\nreturn a vector with the reduced values.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/host_vector.h>\n#include <thrust/reduce.h>\n#include <thrust/unique.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/64", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `void delete_twos(thrust::device_vector<int>& vec)` that removes the elements of\na vector that are equal to 2 using a Thrust algorithm.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/remove.h>\n#include <cstddef>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/65", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `thrust::device_vector<int>::iterator\nfind_first_negative(thrust::device_vector<int>& vec)` that finds and returns an iterator to the\nfirst element of the input vector that is negative.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/find.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/66", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `void all_42s(thrust::device_vector<int>& vec)` that flls the input vector all with\n42s using a thrust algorithm.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/fill.h>\n#include <cstddef>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/67", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `std::size_t find_divergence(thrust::device_vector<int>\nconst &vec1, thrust::device_vector<int> const &vec2)` that  detects the first index where the input\nvectors are not equal and returns the index using one thrust algorithm.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/host_vector.h>\n#include <thrust/mismatch.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/68", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `thrust::device_vector<int> neighbors_difference(thrust::device_vector<int> const&\nvec)` that computes the difference between every input element with its previous element using one\nthrust algorithm. For the first element just copy it as is.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/adjacent_difference.h>\n#include <thrust/device_vector.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/69", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `void square_indices(thrust::device_vector<int> &vec);` that fills the input vector\nwith the squares of the indices using one thrust algorithm.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/host_vector.h>\n#include <thrust/tabulate.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/70", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `void stable_sort_pairs(const thrust::device_vector<thrust::pair<int, char>> &vec)`\nthat sorts the input vector on GPU in increasing order according to the first element of the pair by\nmaintaining the relative order of the elements using a single thrust algorithm.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/execution_policy.h>\n#include <thrust/host_vector.h>\n#include <thrust/pair.h>\n#include <thrust/sort.h>\n#include <thrust/tuple.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/71", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `bool is_divided(thrust::device_vector<int> const& vec1)` that accepts a device\nvector and checks whether it is divided properly such that all even numbers appear before all odd\nnumbers using a single thrust algorithm.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/partition.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/72", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `bool check_equality(thrust::device_vector<int>&\nvec1, thrust::device_vector<int>& vec2)` that checks whether two vectors are equal on device using a\nthrust algorithm.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/equal.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/73", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `bool is_arranged_in_order(const thrust::device_vector<int>& vec)` that checks if\ndevice input vector elements are in order using a thrust algorithm.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/execution_policy.h>\n#include <thrust/sort.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/74", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `thrust::device_vector<int> vector_difference(thrust::device_vector<int> const&\nvec1, thrust::device_vector<int> const& vec2)` that removes all the elements of the sorted vector\nvec2 from the sorted vector vec1 using one thrust algorithm. Returns the difference vector as a\nresult.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/set_operations.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/75", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `int how_many_threes(thrust::device_vector<int> const& vec)` that counts how many\noccurances of the number three are there in the input vector using a thrust algorithm.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/count.h>\n#include <thrust/device_vector.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/76", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `int how_many_negatives(thrust::device_vector<int> const& vec)` that counts how\nmany negative numbers are there in the input vector using a thrust algorithm.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/count.h>\n#include <thrust/device_vector.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/77", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `void copy_first_n(const thrust::device_vector<int>& src,\nthrust::device_vector<int>& dst, int n)` that copies the first n elements of a src vector in GPU to\na dst vector in GPU using a thrust algorithm that efficiently transfers a specific number of\nelements. The function should utilize an appropriate thrust method for copying a fixed number of\nelements.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/copy.h>\n#include <thrust/device_vector.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/78", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `bool all_positives(thrust::device_vector<int> const& vec)` that checks whether\nall values in a vector are positive using a Thrust algorithm.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/logical.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/79", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function `void mix_and_scramble(thrust::device_vector<int>& vec)` that\ntakes an input vector and reorders the elements in a random way using one thrust algorithm.\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <thrust/device_vector.h>\n#include <thrust/shuffle.h>\n#include <thrust/sort.h>\n#include <cstdlib>\n#include <fstream>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/80", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel to compute the dot product of two vectors using shared memory.\n \nThe signature of the function is __global__ void k_dotProduct(const int *inputVectorA, const int *inputVectorB, int *resultDotProduct, const int n).\n\n>>> k_dotProduct({1, 2, 3, 4}, {1, 0, 0, 1}, resultDotProduct, 4) -> resultDotProduct: 5\n>>> k_dotProduct({1, 2, 3, 4, 5, 6, 7, 8, 9}, {1, 0, 0, 1, 0, 0, 1, 0, 0}, resultDotProduct, 9) -> resultDotProduct: 12 \n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cuda_runtime.h>\n#include <algorithm>\n#include <cstdio>\n#include <assert.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/81", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel to transpose a NxN square matrix in-place using statically allocated shared memory. Assume that the block size is pre-defined as a constant BLOCK_SIZE. The signature of the function is __global__ void k_transposeMatrix(int* matrix, const int height, const int width).\n\nThe matrix transpose needs to be computed in-place without creating a copy of the original matrix.\n\n>>> k_transposeMatrix({{1, 2, 3}, {4, 5, 6}, {7, 8, 9}}, 3, 3) -> {{1, 4, 7}, {2, 5, 8}, {3, 6, 9}}\n>>> k_transposeMatrix({{1, 2}, {3, 4}}, 2, 2) -> {{1, 3}, {2, 4}}\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cuda_runtime.h>\n#include <cstdio>\n#include <assert.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/82", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel to find minimum and maximum values in a vector. The kernel needs to use warp shuffles, reductions and atomics in finding minimum and maximum values in the vector.\n\nThe signature of the kernel is __global__ void k_findMinMax(int* data, int* minResult, int* maxResult, int n).\n\n>>> k_findMinMax({2, 1, 5, 4}) -> min: 1 and max: 5\n>>> k_findMinMax({9, 3, 3, 5, 2, 8, 3, 10, 21}) -> min: 2 and max: 21 \n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <iostream>\n#include <limits.h>\n#include <cuda_runtime.h>\n#include <algorithm>\n#include <assert.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/83", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a function that uses the cuBLAS library to compute the Euclidean distances between two vectors.\n\nThe signature of the function is float calculateEuclideanDistance(float* inputVectorA_d, float* inputVectorB_d, int n, cudaStream_t stream, cublasHandle_t handle), where inputVectorA_d and inputVectorB_d are device pointers to the input vectors, n is the number of elements in the vectors, the stream is the CUDA stream for asynchronous execution, and the handle is the cuBLAS handle for managing cuBLAS operations.\n\n>>> calculateEuclideanDistance({41.48, 79.25, 93.81, 75.60, 72.91, 39.09, 34.96, 88.32, 32.21, 95.47}, {7.21, 1.02, 95.87, 61.54, 99.16, 25.89, 85.60, 87.90, 12.21, 22.57}, 10) -> 128.991\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cstdio>\n#include <algorithm>\n#include <cuda_runtime.h>\n#include <cublas_v2.h>\n#include <assert.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/84", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel to perform a Linear Translation using unified memory, where each thread updates the coordinates (x, y, z) by applying translation offsets.\n\nThe signature of function is __global__ void k_translatePoints(float* x_coords, float* y_coords, float* z_coords, float tx, float ty, float tz, int size).\n\n>>> k_translatePoints({0,1,2,3,4}, {0,1,2,3,4}, {0,1,2,3,4}, 1, 1, 1, 5) -> x_coords: {1,2,3,4,5}, y_coords: {1,2,3,4,5}, z_coords: {1,2,3,4,5})\n>>> k_translatePoints({0,1,2,3,4,5,6,7,8,9}, {0,1,2,3,4,5,6,7,8,9}, {0,1,2,3,4,5,6,7,8,9}, 0.1, 0.2, 0.3, 10) -> x_coords: {0.1,1.1,2.1,3.1,4.1,5.1,6.1,7.1,8.1,9.1}, y_coords: {0.2,1.2,2.2,3.2,4.2,5.2,6.2,7.2,8.2,9.2}, z_coords: {0.3,1.3,2.3,3.3,4.3,5.3,6.3,7.3,8.3,9.3} \n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cuda_runtime.h>\n#include <assert.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/85", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nCreate a CUDA kernel for RGB to grayscale conversion, where each thread processes a single pixel using a weighted sum of RGB channels.\n\nThe signature of the functions is __global__ void k_rgbToGrayscaleKernel(unsigned char* rgbInput_d, float* weights_d, unsigned char* grayscaleOutput_d, int width, int height), where rgbInput_d is input pixels of RGB, weights_d is the weights for RGB conversion, grayscaleOutput_d is converted grayscale output, width & height are the dimension of the image.\n\n>>> k_rgbToGrayscaleKernel({{255, 0, 0}, {0, 255, 0}, {0, 0, 255}, {255, 255, 0}, {255, 255, 255}}, {0.299, 0.587, 0.114}, grayscaleOutput_d, 5, 1)-> grayscaleOutput_d: ({76, 149, 29, 225, 255})\n>>> k_rgbToGrayscaleKernel({{123, 231, 12}, {45, 67, 89}, {190, 12, 220}, {12, 180, 45}, {255, 123, 89}}, {0.299, 0.587, 0.114}, grayscaleOutput_d, 5, 1)-> grayscaleOutput_d: ({173, 62, 88, 114, 158}) \n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cuda_runtime.h>\n#include <cstdio>\n#include <assert.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/86", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel k_sumSpectralBands using managed memory to perform summation across spectral bands for each pixel in a 3D hyperspectral data cube. The kernel should reduce the 3D data cube (height \u00d7 width \u00d7 bands) to a 2D output (height \u00d7 width) by summing along the spectral bands, optimizing for real-time processing of large datasets.\n\nThe signature of the function is __global__ void k_sumSpectralBands(float* inputData_d, float* outputData_d, int x_dim, int y_dim, int z_dim).\n\n>>> k_sumSpectralBands({10, 20, 30, 15, 25, 35, 11, 21, 31, 9, 19, 29}) -> ({60, 75, 63, 57})\n>>> k_sumSpectralBands({5, 15, 25, 10, 20, 30, 7, 17, 27, 12, 22, 32}) -> ({45, 60, 51, 66}) \n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cuda_runtime.h>\n#include <assert.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/87", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel to apply a 3x3 sharpening filter. Each thread computes one pixel for efficient access to neighboring pixels and handles zero-padding at image boundaries.\n\nSharpening Kernel = [0  -1  0\n                     -1  5  -1\n                     0  -1  0]  \n\nThe signature of the function is __global__ void k_sharpenImage(const unsigned char* inputImage, unsigned char* outputImage, int width, int height).\n\n>>> k_sharpenImage({10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200,210,220,230,240,250}, outputImage, 5, 5) -> outputImage: {0,0,10,30,110,110,70,80,90,210,210,120,130,140,255,255,170,180,190,255,255,255,255,255,255}\n>>> k_sharpenImage({255,254,253,252,251,250,249,248,247,246,245,244,243,242,241,240,239,238,237,236,235,234,233,232,2310},outputImage, 5, 5) -> outputImage: {255,255,255,255,255,255,249,248,247,255,255,244,243,242,255,255,239,238,237,255,255,255,255,255,255} \n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cuda_runtime.h>\n#include <cstdio>\n#include <assert.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/88", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel for 1D signal convolution filter with smoothing and boundary condition handling.\n\nThe signature of the function is __global__ void k_convolve1D(const float* signal, const float* filter, float* output, int signalLen, int filterLen).\n\n>>> k_convolve1D({3.0f, 1.0f, 4.0f, 1.0f, 5.0f, 9.0f, 2.0f, 6.0f, 5.0f, 3.0f}, {0.25, 0.5, 0.25}, output, 10, 3)-> output: ({0.75, 1.75, 2.25, 2.50, 2.75, 5.00, 6.25, 4.75, 4.75, 4.75})\n>>> k_convolve1D({1, 2, 3, 4, 5, 6, 7, 8, 9, 10}, {0.25, 0.5, 0.25}, output, 10, 3)-> output: ({0.25, 1.00, 2.00, 3.00, 4.00, 5.00, 6.00, 7.00, 8.00, 9.00}) \n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cuda_runtime.h>\n#include <cstdio>\n#include <assert.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/89", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel to find the L2 norm of a vector that utilizes shared memory, atomic operations, and reduction.\n\nThe signature of the function is __global__ void k_l2Norm(float *input, float *result, int n, bool square), where input is a vector for which L2 norm need to be calculated, result is a pointer where the output is stored, n is the total number of elements in the vector, and square controls whether the elements are squared before summing or summed directly.\n\n\n>>> k_l2Norm({2, 5, 1, 8}, result, 4, true) -> result: 9.695360\n>>> k_l2Norm({3, 9, 5, 7}, result, 4, true) -> result: 12.806249\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cuda_runtime.h>\n#include <algorithm>\n#include <cstdio>\n#include <cmath>\n#include <assert.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/90", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nBy leveraging CUDA device memory, write a CUDA kernel to find the distance of two sets of geographical coordinates, A and B. Here, $A=((lat_{a0}, long_{a0}), (lat_{a1}, long_{a1}), (lat_{a2}, long_{a2}), \\cdots (lat_a{n-1}, long_a{n-1}))$ and $B=((lat_{b0}, long_{b0}), (lat_{b1}, long_{b1}), (lat_{b2}, long_{b2}), \\cdots , (lat_b{n-1}, long_b{n-1}))$.\nThe distance between each pair of A and B should be in kilometers, such as $Output = (dist(a_0, b_0), dist(a_1,b_1), dist(a_2,b_2) \\cdots )$ in km, here each $a_i = (lat_{ai}, long_{ai})$, and each $b_i = (lat_{bi}, long_{bi})$.\n\nThe signature of the kernel is __global__ void k_GeoDistance(double *lat1, double *lon1, double *lat2, double *lon2, double *result, int n) where lat1 and lon1  are arrays containing the latitudes and longitudes of the first set of coordinates, lat1 and lon1  are arrays containing the latitudes and longitudes of the second set of coordinates, result is an array where the calculated distances will be stored, n is the number of coordinate pairs to process.\n\n>>> k_MatrixMul(A{1,2,3}{4,5,6}, B{7,8}{9,10}{11,12}) --> Output{58,64}{139,154}\n>>> k_MatrixMul(A{1,0,2}{-1,3,1}{2,-2,0}, B{3,1,2}{2,1,1}{1,0,1}) --> Output{5,1,4}{4,2,4}{4,0,4} \n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <stdio.h>\n#include <math.h>\n#include <assert.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/91", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel to calculate the signal power, where each thread computes the power of an element in an input signal by squaring its amplitude.\n\nThe signature of the function is __global__ void k_computeSignalPower(float* outputSignal_d, const float* inputSignal_d, int size), where outputSignal_d is the array storing the computed power values, inputSignal_d is the array containing the original amplitude values, and size represents the length of both arrays.\n\n>>> k_computeSignalPower(outputSignal_d, {0.0f, 1.0f, 2.0f, 3.0f, 4.0f, 5.0f, 6.0f, 7.0f, 8.0f, 9.0f}, 10) -> outputSignal_d: ({0.0f, 1.0f, 4.0f, 9.0f, 16.0f, 25.0f, 36.0f, 49.0f, 64.0f, 81.0f})\n>>> k_computeSignalPower(outputSignal_d, {2.3f, 6.9f, 1.5f, 8.1f, 3.6f, 4.8f, 7.4f, 5.0f, 9.3f, 0.4f}, 10) -> outputSignal_d: ({5.29f, 47.61f, 2.25f, 65.61f, 12.96f, 23.04f, 54.76f, 25.0f, 86.49f, 0.16f}) \n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cuda_runtime.h>\n#include <cstdio>\n#include <cassert>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/92", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel to compute the difference between current and background images using managed memory.\n\nThe signature of the function is __global__ void k_backgroundSubtraction(float* currentImage, float* backgroundImage, float* output, int width), where currentImage is a pointer to the current image data array, backgroundImage is a pointer to the  back ground image data array, the output is an array with the subtraction results, and width is the number of elements of the arrays being processed.\n\n>>> k_backgroundSubtraction({100, 101, 102, 103, 104, 105, 106, 107, 108, 109}, {100, 102, 101, 105, 103, 110, 106, 105, 110, 108}, output, 10)-> output: ({0, 1, -1, 2, -1, 5, 0, -2, 2, -1})\n>>> k_backgroundSubtraction({50, 55, 60, 65, 70, 75, 80, 85, 90, 95}, {52, 54, 61, 67, 69, 78, 81, 83, 91, 97}, output, 10)-> output: ({2, -1, 1, 2, -1, 3, 1, -2, 1, 2}) \n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cuda_runtime.h>\n#include <cstdio>\n#include <cassert>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/93", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel to convert polar coordinates (radius, angle) into Cartesian coordinates (x, y) using data parallelism to efficiently convert multiple polar coordinates. \nThe Cartesian coordinates are computed as \\( x = r \\cos(\\text{angle}) \\) and \\( y = r \\sin(\\text{angle}) \\).\n\nThe signature of the kernel is __global__ void k_polarToCartesian(float* radius, float* angle, float* x, float* y, int n), where the radius is an input array of radial distances, angle is an input array of angles in radians, x is an output array for Cartesian x-coordinates, y is an output array for Cartesian y-coordinates, and n is the total number of coordinates to convert.\n\n>>> k_polarToCartesian({2.5, 3.0, 4.0}, {0.2, 0.6, 1.0}, x, y, 3) -> {x: {2.45017, 2.47601, 2.16121} y:{0.49667, 1.69393, 3.36588}}\n>>> k_polarToCartesian({1.5, 2.0, 3.5, 4.5, 5.5}, {0.3, 0.7, 1.1, 1.5, 1.9}, x, y, 5) -> {x: {1.433, 1.52968, 1.58759, 0.318317, -1.77809},  y:{0.44328, 1.28844, 3.11923, 4.48873, 5.20465}}\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cuda_runtime.h>\n#include <algorithm>\n#include <cmath>\n#include <cstdio>\n#include <cassert>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/94", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel to join two large images side-by-side, processing each pixel in parallel and designed to handle large datasets.\n\nThe signature of the function is __global__ void k_joinImages(const unsigned char* image1_d, const unsigned char* image2_d, unsigned char* outputImage_d, int width, int height), where image1_d is the array of first image, image2_d is the array of second image, outputImage_d is the array of joined images, and width and height specify the dimensions of both input images.\n\n>>> k_joinImages({{1,2,3}, {4,5,6}, {7,8,9}, {10,11,12}}, {{5,6,7}, {8,9,10}, {11,12,13}, {14,15,16}}, outputImage_d, 3, 4) -> outputImage_d: ({{1,2,3,5,6,7},{4,5,6,8,9,10},{7,8,9,11,12,13},{10,11,12,14,15,16}})\n>>> k_joinImages({{1,2,3,4,5}, {6,7,8,9,10}, {11,12,13,14,15}, {16,17,18,19,20}}, {{5,6,7,8,9}, {10,11,12,13,14}, {15,16,17,18,19}, {20,21,22,23,24}},outputImage_d, 5, 4) -> outputImage_d: ({{1,2,3,4,5,5,6,7,8,9}, {6,7,8,9,10,10,11,12,13,14}, {11,12,13,14,15,15,16,17,18,19}, {16,17,18,19,20,20,21,22,23,24}})\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cuda_runtime.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <assert.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/95", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel to estimate the value of $\\pi$ using the Monte Carlo simulation method. Utilize shared memory for local reduction of points that fall inside the unit circle.\n\nThe signature of the function is __global__ void k_monteCarlo(int *blockCount_d, int num_points), where blockCount_d is an array that holds the number of points within the circle for each corresponding block, and num_points represents the total number of points used in the simulation.\n\n>>> k_monteCarlo(40, 10000) -> 3.13744\n>>> k_monteCarlo(1563, 400000) -> 3.1466\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <limits>\n#include <cstdio>\n#include <cuda.h>\n#include <curand_kernel.h>\n#include <cuda_runtime.h>\n#include <algorithm> // For std::max_element\n#include <cassert>\n#include <assert.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/96", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel that applies a rotation transformation to a 2D image using a specified angle theta, where each thread calculates the rotated position of a pixel and maps it to the corresponding input pixel, ensuring proper boundary handling.\n\nThe signature of the function is __global__ void k_rotateImage(float* image_d, float* rotatedImage_d, float angle, int width, int height), where image_d is the input image in row-major order, rotatedImage_d is the output image in row-major order, theta is the rotation angle in radians, width and height specify the dimensions of the image.\n\n>>> k_rotateImage({1,2,3,4,5,6,7,8,9}, rotatedImage_d, 0.707, 3, 3) -> rotatedImage_d: ({4,1,2,7,5,3,8,9,6})\n>>> k_rotateImage({1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16}, rotatedImage_d, 0.707, 4, 4)-> rotatedImage_d: ({0,5,0,2,13,9,6,3,0,14,11,8,0,15,16,12}) \n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cuda_runtime.h>\n#include <cstdio>\n#include <assert.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/97", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel to calculate the Kronecker product of two matrices. Each thread should compute an element in the Kronecker product matrix.\n\nThe signature of the kernel is __global__ void k_kroneckerProduct(float* matrixA_d, float* matrixB_d, float* matrixKronProd_d, int matARowsize, int matAColsize, int matBRowsize, int matBColsize), where matrixA_d is the pointer to the input matrix A, matrixB_d is the pointer to the input matrix B, matrixKronProd_d is the Kronecker product output of matrix A and matrix B, matARowsize, matBRowsize are the number of rows of matrix A, matrix B respectively while matAColsize, matBColsize are the number of columns of matrix A, matrix B respectively.\n\n>>> k_kroneckerProduct({{1, 2}, {3, 4}}, {{0, 5}, {6, 7}}, matrixKronProd_d, 2, 2, 2, 2) -> matrixKronProd_d:{{0, 5, 0, 10}, {6, 7, 12, 14}, {0, 15, 0, 20}, {18, 21, 24, 28}}\n>>> k_kroneckerProduct({{1}, {2}, {3}}, {{1, 2}, {3, 4}},  matrixKronProd_d, 3, 1, 2, 2) -> matrixKronProd_d:{{1, 2}, {3, 4}, {2, 4}, {6, 8}, {3, 6}, {9, 12}}\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cstdio>\n#include <algorithm>\n#include <assert.h>\n#include <cuda_runtime.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/98", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nImplement a CUDA kernel to generate a heatmap. Each kernel thread should compute an element in the input array, using minimum and maximum boundary values to clamp and normalize the data.\n\nThe signature of the CUDA kernel is __global__ void k_generateHeatmap(float * input_d, unsigned char * output_d, const float minValue, const float maxValue, const int numElementsX, const int numElementsY), where minValue and maxValue are the boundaries of input data values.\n\n>>> k_generateHeatmap({-1500.0f, -1650.0f, -1800.0f, -1950.0f, -2100.0f, 2250.0f, 2400.0f, 2550.0f, 2700.0f, 2850.0f }, output_d, 1900.0f, 2800.0f, 10, 1) -> output_d:{ 0, 0, 0, 14, 57, 99, 142, 184, 227, 255 }\n>>> k_generateHeatmap({-1.0f, -0.8f, -0.6f, -0.4f, -0.2f, 0.0f, 0.2f, 0.4f, 0.6f, 0.8f }, output_d, -1.0f, 1.0f, 10, 1) -> output_d:{ 0, 25, 51, 77, 102, 128, 153, 179, 204, 230 }\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <assert.h>\n#include <stdio.h>\n#include <vector>\n#include <cuda.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/99", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel that adjust brightness of an image leveraging data parallelism. Each thread processes a pixel by multiplying it with a brightness factor. If the resulting value exceeds the upper or lower thresholds, it is clamped to ensure the output remains within valid bounds, effectively saturating the result.\n\nThe signature of the function is __global__ void k_adjustBrightness(const float* inputImage, int upperThreshold, int lowerThreshold, float brightnessFactor, float *outputImage, int size), where inputImage is the pointer to the input image, UpperThreshold and lowerThreshold are the thresolds to ensure output is within valid values , brightnessFactor is a scaling factor to adjust brightness, outputImage is the pointer to the brightness adjusted output image, and size is total number of pixels in input image.\n\n>>> k_adjustBrightness({244.1642, 246.0466, 40.1913, 247.5012, 244.0776, 123.7708, 204.0715, 36.1810}, 250, 5, 0.7577, *outputImage, 8) -> ({185.0032, 186.4295, 30.4529, 187.5317, 184.9376, 93.7811, 154.6250, 27.4143})\n>>> k_adjustBrightness({107.5491, 233.5126, 202.0129, 244.6706, 167.2139, 9.1065, 216.5280, 238.1683, 189.4988, 100.0179}, 245, 10, 0.95, *outputImage, 10) -> ({102.1716, 221.8370, 191.9123, 232.4371, 158.8532, 10.0000, 205.7016, 226.2599, 180.0239, 95.0170})\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cstdio>\n#include <algorithm>\n#include <cuda_runtime.h>\n#include <assert.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/100", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel that transforms from image positions to Geo coordinates, where each thread calculates the Geo coordinates for a corresponding pixel positions using geometric transformation:\n\nlatitude = extentWidth + imgX / (imgWidth-1) + extentLeft\nlongitude = extentHeight + imgY / (imgHeight-1) + extentTop.\n\nThe signature of the function is __global__ void k_imagePosToGeoCoord(float* imgX_d, float* imgY_d, float* lat_d, float* long_d, const float4 geoTransform, int width, int height, int imgWidth, int imgHeight), where imgX_d and imgY_d are arrays containing the image coordinates, lat_d and long_d are arrays in which the transformed world coordinates will be stored, width and height define the dimensions of the region to process within the image, while imgWidth and imgHeight represent the original image dimensions used for normalizing the coordinates.\n\n>>> k_imagePosToGeoCoord({0, 71, 142, 213, 284, 355, 426, 497, 568, 639}, {0, 53, 107, 160, 213, 267, 320, 373, 427, 479}, latitude, longitude, {73.25, 23.5, 0.35, 0.25}, 10, 1, 640, 480) -> (latitude: {73.25, 73.2889, 73.3278, 73.3667, 73.4056, 73.4444, 73.4833, 73.5222, 73.5611, 73.6}, longitude:{23.5, 23.5277, 23.5558, 23.5835, 23.6112, 23.6394, 23.667, 23.6947, 23.7229, 23.75})\n>>> k_imagePosToGeoCoord({0, 50, 100, 150, 200, 250, 300, 350, 400, 450}, {0, 50, 100, 150, 200, 250, 300, 350, 400, 450}, latitude, longitude, {73.75, 23.5, 0.35, 0.25}, 10, 1, 640, 480) -> (latitude: {73.75, 73.7774, 73.8048, 73.8322, 73.8595, 73.8869, 73.9143, 73.9417, 73.9691, 73.9965}, longitude:{23.5, 23.5261, 23.5522, 23.5783, 23.6044, 23.6305, 23.6566, 23.6827, 23.7088, 23.7349}) \n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <assert.h>\n#include <cstdio>\n#include <cuda_runtime.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/101", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel that performs in place bitonic sort on a dataset. The kernel will use each thread to load a single element and compare it with adjacent elements within a block.\n\nThe signature of the function is __global__ void k_bitonicSort(float* inputData, int size), where inputData is the pointer to the unsorted input and sorted output array, and size denotes the array length of inputData.\n\n>>> k_bitonicSort({4.5, 3, 7.2, 5, 2.1}, 5) => ({2.1, 3, 4.5, 5, 7.2})\n>>> k_bitonicSort({12, 9.5, 15.3, 3, 5.8, 8}, 6) => ({3, 5.8, 8, 9.5, 12, 15.3})\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cstdio>\n#include <cfloat>\n#include <algorithm>\n#include <cuda_runtime.h>\n#include <assert.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/102", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nDevelop a CUDA kernel to convert the signal from the time domain to the frequency domain using the FFT(Fast Fourier Transform) algorithm. Utilize the device memory to reuse the data for every stage of the FFT.\n\nThe signature of the CUDA kernel is __global__ void k_fftButterfly(float *real_d, float *imag_d, int numElements, int logNumElements), where real_d and image_d are real and imaginary components of input complex number, numElements is the number of elements in the real_d & imag_d arrays, logNumElements is log of input size used for a number of stages in FFT.\n\n>>> k_fftButterfly(real_d{ 1,2,3,4 }, imag_d{ 0,0,0,0 }, 4, 2) --> {real_d{ 10.00000, -2.00000, -2.00000, -2.00000 } imag_d{ 0.00000, 2.00000, 0.00000, -2.00000 } }\n>>> k_fftButterfly(real_d{ 1, 2, 3, 4, 5, 6, 7, 8 }, imag_d{ 0, 0, 0, 0, 0, 0, 0, 0 }, 8, 3) --> {real_d{ 36.00000, -4.00000, -4.00000, -4.00000,-4.00000, -4.00000, -4.00000, -4.00000} imag_d{0.00000, 9.65685, 4.00000, 1.65685, 0.00000, -1.65685, -4.00000, -9.65685 } }\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <assert.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <math.h>\n#include <cuda_runtime.h>\n#include <cooperative_groups.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/103", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel to compute the total electromagnetic energy and net acceleration of a system of charged particles using a parallel reduction technique in shared memory, where each thread is responsible for computing the properties of a single particle. Each particle is defined by its mass, charge, three position components, and three velocity components in 3D space.\n\nThe kernel should adhere to the following signature: __global__ void k_computeElectromagneticEnergy(float* mass_d, float* charge_d, float* posX_d, float* posY_d, float* posZ_d, float* velocityX_d, float* velocityY_d, float* velocityZ_d, float* accX_d, float* accY_d, float* accZ_d, float* energy_d, unsigned int particleCount, unsigned int blockSize). Here, mass_d and charge_d are pointers to arrays containing the mass and charge of each particle, respectively; posX_d, posY_d, and posZ_d are arrays containing the x, y, and z components of each particle's position; velocityX_d, velocityY_d, and velocityZ_d are arrays containing the x, y, and z components of each particle's velocity; accX_d, accY_d, and accZ_d are arrays for storing the computed x, y, and z components of each particle's acceleration; energy_d is a pointer to an array storing the electromagnetic energy of each particle; and particleCount is the total number of particles in the system.\n\n>>> k_computeElectromagneticEnergy(mass_d:{9.377778e+00, 4.188704e+00}, charge_d:{3.666271e-07, -1.343065e-07 }, PosX_d:{7.557432e+00, 5.920792e+00}, PosY_d:{2.663286e+00, 9.004688e+00}, PosZ_d:{7.831457e+00, -9.574142e+00}, VelX_d:{4.866964e+00, 1.766176e-01}, VelY_d:{3.788892e+00, 2.608461e+00}, VelZ_d:{3.423035e+00, 8.226066e-01}, accX_d, accY_d, accZ_d, energy_d,particleCount:{2}) -> AccX:{1.201183e-08, -2.689238e-08}, AccY:{-4.654157e-08, 1.041984e-07}, AccZ:{1.277452e-07, -2.859992e-07}, energy_d: 2.490527e+02\n>>> k_computeElectromagneticEnergy(mass_d:5.075351e+00, 7.386061e+00, 4.689754e+00}, charge_d:{4.102964e-07, -1.551322e-07, -9.556600e-07}, PosX_d:{-9.194314e+00, 3.681394e+00, 9.178165e+00}, PosY_d:{ -5.453526e+00, -8.182205e+00, 9.368402e+00}, PosZ_d:{6.816517e+00, -2.430100e+00, 1.251886e+00}, VelX_d:{2.445421e+00, -1.954804e+00, 3.721204e+00}, VelY_d:{3.764471e+00, -2.396704e+00, -4.160023e+00}, VelZ_d:{1.780605e-01, 4.350655e+00, -2.173305e+00}, accX_d, accY_d, accZ_d, energy_d,particleCount:{3}) -> AccX:{-1.243298e-06, 3.900122e-07, 7.312794e-07}, AccY:{-6.476981e-07, 4.291686e-07, 2.503966e-08}, AccZ:{5.214195e-07, -7.143858e-08, -4.517800e-07}, energy_d: 2.405715e+02\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <assert.h>\n#include <cuda_runtime.h>\n#include <iomanip>\n#include <iostream>\n#include <random>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/104", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel to simulate temperature distribution across a 2D plate where each boundary point has a fixed temperature, and the plate has a thickness of one element. The kernel should utilize device memory to reuse data and update inner temperatures based on the average of the top, bottom, left, and right temperatures in each iteration of the simulation.\n\nThe signature of the function is __global__ void k_temperatureDistribution(float *temperatureValues, int numPlateElementsX, int numPlateElementsY, int numIterations), where temperatureValues is the array to the current temperature of plate, numPlateElementsX is the number of elements along the x-axis of the plate, numPlateElementsY is the number of elements along the y-axis of the plate, and numIterations is the number of iterations to simulate the temperature distribution.\n\n>>> k_temperatureDistribution(temperatureValues: {320.0, 320.0, 320.0, 320.0, 320.0, 0.0, 0.0, 320.0, 320.0, 0.0, 0.0, 320.0, 320.0, 320.0, 320.0, 320.0}, 4, 4, 3) -> temperatureValues: {320.0, 320.0, 320.00, 320.0, 320.0, 280.0, 280.0, 320.0, 320.0, 280.0, 280.0, 320.0, 320.0, 320.0, 320.0, 320.0}\n>>> k_temperatureDistribution(temperatureValues: {360.0, 366.667, 373.333, 380.0, 386.667, 460.0, 0.0, 0.0, 0.0, 393.333, 453.333, 0.0, 0.0, 0.0, 400.0, 446.667, 0.0, 0.0, 0.0, 406.667, 440.0, 433.333, 426.667, 420.0, 413.333}, 5, 5, 2) -> temperatureValues: {360.000000, 366.666656, 373.333313, 379.999969, 386.666626, 459.999847, 258.333282, 193.333313, 241.666641, 393.333282, 453.333191, 219.999939, 103.333313, 199.999969, 399.999939, 446.666534, 274.999939, 213.333282, 258.333282, 406.666595, 439.999878, 433.333221, 426.666565, 419.999908, 413.333252}\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cstdio>\n#include <algorithm>\n#include <cstring>\n#include <cuda_runtime.h>\n#include <assert.h>\n#include <cooperative_groups.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/105", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel to upscale a 2D grayscale image from specified input dimensions to target output dimensions using bilinear interpolation by leveraging shared memory to cache input data tiles that are reused across multiple threads within a block.\n\nThe signature of the function is __global__ void k_bilinearInterpolation(float *inputMat, int inputWidth, int inputHeight, float *outputMat, int outputWidth, int outputHeight), where inputMat_h is the pointer to the input image array, inputWidth and inputHeight are dimensions (width & height) of the input image, respectively, outputMat is the pointer to the output array, and outputWidth & outputHeight are dimensions (width & height) of interpolated output image array.\n\n>>> k_bilinearInterpolation({{0.0, 0.1, 0.2, 0.3, 0.4}, {0.5, 0.6, 0.7, 0.8, 0.9}, {0.10, 0.11, 0.12, 0.13, 0.14}, {0.15,0.16,0.17,0.18,0.19},{0.20,0.21,0.22,0.23,0.24}}, 5, 5, outputMat, 8, 8) -> outputMat:{{0.00, 0.06, 0.11, 0.17, 0.23, 0.29, 0.34, 0.40}, {0.29, 0.33, 0.44, 0.43, 0.54, 0.53, 0.64, 0.69}, {0.44, 0.49, 0.54, 0.59, 0.64, 0.69, 0.74, 0.79}, {0.21, 0.23, 0.26, 0.27, 0.30, 0.31, 0.34, 0.36}, {0.11, 0.12, 0.13, 0.13, 0.14, 0.14, 0.15, 0.15}, {0.14, 0.15, 0.16, 0.16, 0.17, 0.17, 0.18, 0.18}, {0.17, 0.18, 0.19, 0.19, 0.20, 0.20, 0.21, 0.21}, {0.20, 0.21, 0.21, 0.22, 0.22, 0.23, 0.23, 0.24}}\n>>> k_bilinearInterpolation({{0.0, 0.1, 0.2}, {0.3, 0.4, 0.5}, {0.6, 0.7, 0.8}, {0.9, 0.10, 0.11}, {0.12, 0.13, 0.14}}, 3, 5, outputMat, 7, 11) -> outputMat: {{0.00, 0.03, 0.07, 0.10, 0.13, 0.17, 0.20}, {0.12, 0.17, 0.17, 0.22, 0.27, 0.27, 0.32}, {0.24, 0.30, 0.28, 0.34, 0.40, 0.38, 0.44}, {0.36, 0.40, 0.42, 0.46, 0.50, 0.52, 0.56}, {0.48, 0.53, 0.53, 0.58, 0.63, 0.63, 0.68}, {0.60, 0.63, 0.67, 0.70, 0.73, 0.77, 0.80}, {0.72, 0.53, 0.65, 0.46, 0.48, 0.50, 0.52}, {0.84, 0.42, 0.64, 0.22, 0.23, 0.24, 0.25}, {0.74, 0.53, 0.32, 0.11, 0.11, 0.11, 0.12}, {0.43, 0.33, 0.22, 0.12, 0.12, 0.12, 0.13}, {0.12, 0.12, 0.13, 0.13, 0.13, 0.14, 0.14}}\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cuda_runtime_api.h>\n#include <float.h>\n#include <math.h>\n#include <cstdio>\n#include <time.h>\n#include <assert.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/106", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel to separate odd and even indexed elements of an array into different arrays using shared memory for coalesced global memory access while avoiding warp-divergence.\n\nThe signature of the CUDA kernel is __global__ void k_separateOddEven(int *input_d, int *oddData_d, int *evenData_d, int numElements), where input_d is the input vector containing all the input values, oddData_d is output vector for odd-indexed elements in the input_d vector, and evenData_d is output vector for even-indexed elements in the input_d vector.\n\n>>> k_separateOddEven({41, 18467, 6334, 26500, 19169, 15724, 11478, 29358, 26962, 24464}, oddData_d, evenData_d, 10) -> oddData_d: {18467, 26500, 15724, 29358, 24464 }, evenData_d:{ 41, 6334, 19169, 11478, 26962}\n>>> k_separateOddEven({5705, 28145, 23281, 16827, 9961, 491, 2995, 11942, 4827, 5436}, oddData_d, evenData_d, 10) -> oddData_d: {28145, 16827, 491, 11942, 5436 }, evenData_d:{ 5705, 23281, 9961, 2995, 4827}\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <assert.h>\n#include <stdio.h>\n#include <cuda_runtime.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/107", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nImplement a CUDA kernel to generate chaotic results from input elements that are initial conditions, utilizing the logistic map in a data-parallel way.\n\nThe signature of the CUDA kernel is __global__ void k_calculateLogisticMap(float *input_d, float *output_d, int iterations, float growthRate, int numElements), where input_d is a pointer to the array with the input values, output_d is the pointer to store the output array, iterations is the number of times that the logistic map equation is applied, growthRate is the constant to control the dynamics of the map, and numElements is the total number of elements to process them parallel.\n\n>>> k_calculateLogisticMap({0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09}, output_d, 10000, 3.9, 10) -> output_d: {0.0, 0.908595, 0.923597, 0.816154, 0.513786, 0.934181, 0.275205, 0.335843, 0.504806, 0.471532}\n>>> k_calculateLogisticMap({0.0, 0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009}, output_d, 10000, 3.9, 10) -> output_d: {0.0, 0.551224, 0.884021, 0.829637, 0.967275, 0.764777, 0.410691, 0.685051, 0.666282, 0.191851}\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <assert.h>\n#include <stdio.h>\n#include <cuda_runtime.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/108", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel to compute the nearest neighbors of every point in an array-A w.r.t array-B in N-Dimension, where N=3 for 3-Dimension, using shared memory to load array-B and compare it to every point in array-A to find the nearest neighbors.\n\nThe signature of the function is __global__ void k_nearestNeighbors(const float* inputVectorA_d, int nA, float* inputVectorB_d, int nB, int* nearestNeighborIndex), where for every 3D point in inputVectorA_d a nearest neighbour from inputVectorB_d is computed. The sizes of the inputs are given by nA and nB, and the number of nearest neighbors to be calculated is given by nearestNeighborIndex.\n\n>>> k_nearestNeighbors({{-0.38,-2.13,0.69},{-5.7,-4.5,-0.95},{9.23,7.69,9.65}}, 3, {{-9.57,-0.59,8.41},{-6.53,6.68,8.02},{5.11,-9.24,-1.19}},3, nearestNeighborIndex) -> nearestNeighborIndex : {2,0,1}\n>>> k_nearestNeighbors({{-3.44,-0.71,-5.57},{-1.28,-8.79,-5.71},{7.92,2.8,-8.56},{2.07,5.06,-8.3},{-2.45,-9.14,8.19}}, 5,\n    {{9.26,8.7,-4.33},{-8.07,0.91,7.17},{-5.81,-3.63,-7.7},{-8.4,2.07,-8.9}}, 4, nearestNeighborIndex) -> nearestNeighborIndex : {2,2,0,0,1}\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cuda_runtime.h>\n#include <limits.h>\n#include <stdlib.h>\n#include <float.h>\n#include <cstdio>\n#include <assert.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/109", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel that computes the Peak Signal-to-Noise Ratio (PSNR) between an original image and its compressed version using shared memory.\n\nThe signature of the kernel is __global__ void k_peakSignalToNoiseRatio(float *inputImage, float *compressedInputImage, float *peakToNoiseRatio, int imageWidth, int imageHeight), where inputImage is the pointer to the input image in row-major order, compressedInputImage is the pointer to compressed input image having same dimensions and format as inputImage, peakToNoiseRatio is the pointer to the output where computed PSNR value will be stored, imageWidth is the width in pixels, and imageHeight is the height in pixels.\n\n>>> k_peakSignalToNoiseRatio({0.452895, 0.403882, 0.69631, 0.452895, 0.403882, 0.69631, 0.452895, 0.403882, 0.69631}, {0.498184, 0.44427, 0.765941, 0.498184, 0.44427, 0.765941, 0.498184, 0.44427, 0.765941}, peakToNoiseRatio, 3, 3) -> peakToNoiseRatio : {25.4613}\n>>> k_peakSignalToNoiseRatio({0.452712, 0.747856, 0.605976, 0.452712, 0.747856, 0.605976, 0.452712, 0.747856}, {0.457239, 0.755335, 0.612036, 0.457239, 0.755335, 0.612036, 0.457239, 0.755335}, peakToNoiseRatio, 4, 2) -> peakToNoiseRatio : {44.2206}\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cstdio>\n#include <algorithm>\n#include <cuda_runtime.h>\n#include <assert.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/110", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nDevelop a CUDA kernel to iteratively solve the distance constraints of joints for a chain under gravitational forces with endpoints pinned to their initial positions. Use the device memory to retain the states of joints until multiple iterations are complete.\nThe signature of the CUDA kernel is __global__ void k_solveConstraintUnderGravity(float *x_d, float *y_d, float *distance_d, float *mass_d, float *xOld_d, float *yOld_d, int numJoints, TempStorage temp), where x_d is a pointer to array of x-coordinate of joints, y_d is a pointer to array of y-coordinate of joints, distance_d is a pointer to array of distances between connected joints, mass_d is a pointer to an array of mass values of joints, xOld_d is a pointer to an array of x-coordinate of joints from previous simulation iteration, yOld_d is a pointer to an array of y-coordinate of joints from previous simulation iteration, and the temp is a struct of temporary arrays used in the algorithm.\n\n>>> k_solveConstraintUnderGravity(\n    { 250.0, 250.366, 255.859, 279.663, 343.75, 478.882, 724.609, 1129.27 },\n    { 140.0, 111.346, 66.4371, 69.6125, 116.323, 139.648, 106.17, 63.8523 },\n    { 28.6559, 45.2441, 24.0146, 79.3034, 137.13, 247.998, 406.87 },\n    { 14.3279, 36.95, 34.6293, 51.659, 108.217, 192.564, 327.434, 203.435 },\n    { 250.0, 250.366, 255.859, 279.663, 343.75, 478.882, 724.609, 1129.27 },\n    { 140.0, 111.346, 66.4371, 69.6125, 116.323, 139.648, 106.17, 63.8523 },\n    8,\n    temp\n) -> x_d: { 250, 250.366, 255.86, 279.663, 343.75, 478.882, 724.609, 1129.27 }, y_d: { 140, 111.347, 66.4372, 69.6154, 116.326, 139.651, 106.173, 63.8523 }\n\n>>> k_solveConstraintUnderGravity(\n    { 0.0, 10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0 },\n    { 0.0, 10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0 },\n    { 14.1421, 14.1421, 14.1421, 14.1421, 14.1421, 14.1421, 14.1421 },\n    { 7.07107, 14.1421, 14.1421, 14.1421, 14.1421, 14.1421, 14.1421, 7.07107 },\n    { 0.0, 10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0 },\n    { 0.0, 10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0 },\n    8,\n    temp\n) -> x_d: { 0.0, 9.99854, 19.9986, 29.9986, 39.9986, 49.9986, 59.9986, 70.0 }, y_d: { 0.0, 10.0015, 20.0015, 30.0015, 40.0015, 50.0015, 60.0015, 70.0 }\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <assert.h>\n#include <stdio.h>\n#include <cuda.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n#include <cooperative_groups.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/111", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel to find the max-score of alignment between two sequences using the Smith-Waterman algorithm. Each block will process one diagonal, and each thread will calculate a unique cell in diagonal based on previously computed neighboring values. Assume that the block size is computed based on the lengths of the sequences.\n\nThe signature of the function is __global__ void k_smithWatermanKernel(char *firstSequence_d, char *secondSequence_d, int length1, int length2, int *scoreMatrix_d, int *maxScore_d), where firstSequence_d is a pointer to the first genome sequence, secondSequence_d is a pointer to the second genome sequence, length1 and length2 are the lengths of first and second genome sequences, scoreMatrix_d is the pointer to integer matrix that stores the intermediate alignment scores and maxScore_d is the pointer to an integer that stores maximum alignment score between the two sequences.\n\n>>> k_smithWatermanKernel(\"GATTACA\", \"GCATGCU\", 7, 7, scoreMatrix_d, maxScore_d)-> maxScore_d: 4\n>>> k_smithWatermanKernel(\"AGCT\", \"CGTACG\", 4, 6, scoreMatrix_d, maxScore_d)-> maxScore_d: 2\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <vector>\n#include <string>\n#include <cstdio>\n#include <algorithm>\n#include <cuda_runtime.h>\n#include <cooperative_groups.h>\n#include <assert.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/112", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel to solve a partial differential equation using red black Gauss-Seidel method. The kernel should utilize device memory to load and update the solution array for each iteration.\n\nThe signature of the function is __global__ void k_solveRedBlackGaussSeidel( float *srcFunction, float *slnFunction, int size, int numIterations) where srcFunction is a pointer to the array containing right-hand side function f(x,y), slnFunction is the pointer to the solution array, size is the length of the square grid, and numIterations specifies how many iterations the solver should run.\n\n>>> k_solveRedBlackGaussSeidel({1, 1, 1, 1}, {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}, 2, 4) -> ({0, 0, 0, 0, 0, -0.0551, -0.0553, 0, 0, -0.0553, -0.0551, 0, 0, 0, 0, 0})\n>>> k_solveRedBlackGaussSeidel({3, 4, 5, 3.5, 4.5, 5.5, 4, 5, 6}, {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0}, 3, 5) -> ({0, 0, 0, 0, 0, 0, -0.1522, -0.2250, -0.1968, 0, 0, -0.2116, -0.3010, -0.2652, 0, 0, -0.1745, -0.2518, -0.2191, 0, 0, 0, 0, 0, 0})\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cstdio>\n#include <algorithm>\n#include <cmath>\n#include <cuda_runtime.h>\n#include <assert.h>\n#include <cooperative_groups.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/113", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel to sort the elements in the array using merge sort method. Implement the kernel using two device functions, the first function should sort the elements within the blocks while the second function should merge all the sorted blocks in to a single sorted array.\n\nThe signature of the kernel is __global__ void k_mergeSort(float *input_d, float *sortedBlocks_d, float *output_d, int numElements), where input_d is the array which contains the elements to be sorted, sortedBlocks_d is the array which contains the sorted elements per block, output_d is the output array which contains the final sorted array elements of size numElements and numElements is the number of elements to be sorted.\n\nThe signature of the First device function is __device__ void d_mergeSortWithinBlock(float *input_d, float *sortedBlocks_d, int numElements), where input_d is the array which contains the elements to be sorted, sortedBlocks_d is the array which contains the sorted elements per block and numElements is the number of elements to be sorted. \n\nThe signature of the second device function is __device__ void d_mergeSortAcrossBlocks(float *sortedBlocks_d, float *output_d, int numElements), where sortedBlocks_d is the array which contains the intermediate sorted elements per block, output_d is the output array which contains the final sorted array elements of size numElements and numElements is the number of elements to be sorted. \n\n>>> k_mergeSort({25.0, 57.0, 2.0, 38.0, 49.0, 11.0, 79.0, 88.0, 5.0, 3.0}, sortedBlocks_d, output_d, 10) -> output_d: {2.0, 3.0, 5.0, 11.0, 25.0, 38.0, 49.0, 57.0, 79.0, 88.0}\n>>> d_mergeSortWithinBlock({25.0, 57.0, 2.0, 38.0, 49.0, 11.0, 79.0, 88.0, 5.0, 3.0}, sortedBlocks_d, 10) -> sortedBlocks_d: {2.0, 25.0, 38.0, 57.0, 11.0, 49.0, 79.0, 88.0, 3.0, 5.0}\n>>> d_mergeSortAcrossBlocks({2.0, 25.0, 38.0, 57.0, 11.0, 49.0, 79.0, 88.0, 3.0, 5.0}, output_d, 10) -> output_d: {2.0, 3.0, 5.0, 11.0, 25.0, 38.0, 49.0, 57.0, 79.0, 88.0}\n>>> k_mergeSort({17.0, 1.0, 15.0, 3.0, 18.0, 2.0, 11.0, 12.0}, sortedBlocks_d, output_d, 8) -> output_d: {1.0, 2.0, 3.0, 11.0, 12.0, 15.0, 17.0, 18.0}\n>>> d_mergeSortWithinBlock({17.0, 1.0, 15.0, 3.0, 18.0, 2.0, 11.0, 12.0}, sortedBlocks_d, 8) -> sortedBlocks_d: {1.0, 3.0, 15.0, 17.0, 2.0, 11.0, 12.0, 18.0}\n>>> d_mergeSortAcrossBlocks({1.0, 3.0, 15.0, 17.0, 2.0, 11.0, 12.0, 18.0}, output_d, 8) -> output_d: {1.0, 2.0, 3.0, 11.0, 12.0, 15.0, 17.0, 18.0}\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cstdio>\n#include <math.h>\n#include <algorithm>\n#include <assert.h>\n#include <float.h>\n#include <cuda_runtime.h>\n#include <cooperative_groups.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/114", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a cuda kernel to perform erosion operation over a binary image. Erosion operation needs to be performed for the given number of iterations. Outputs of each iteration need to be stored on device memory and reused across iterations. \n\nThe signature of the function is __global__ void k_imageErosion(const unsigned char *inputImage_d, const unsigned char *structuringElement_d, unsigned char *outputImage_d, unsigned char *outputImageIntermediateBuffer_d, int inputImageWidth, int inputImageHeight, int structuringElementWidth, int structuringElementHeight, int numberOfErosionIterations), where inputImage_d is a pointer to input image, structuringElement_d is a pointer to structuring element, outputImage_d is a pointer to output image, outputImageIntermediateBuffer_d is a pointer to the additional buffer that is used to store output image. The parameters inputImageWidth and inputImageHeight are the width and height of the input image, structuringElementWidth and structuringElementHeight are the width and height of the structuring element, numberOfErosionIterations specifies the number of iterations of erosion to be performed.\n\n>>> k_imageErosion({1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0},  {1,1,1,1,1,1,1,1,1}, outputImage_d, 5, 5, 3, 3) -> outputImage_d: ({1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0})\n>>> k_imageErosion({0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0},  {1,1,1,1,1,1,1,1,1}, outputImage_d, 5, 5, 3, 3) -> outputImage_d: ({0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0})\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cstdio>\n#include <limits.h>\n#include <assert.h>\n#include <cuda_runtime.h>\n#include <cooperative_groups.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/115", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nCreate a CUDA kernel to simulate 2D wave propagation using the finite-difference method while utilizing device memory to access all intermediate states of the data. Implement reflective boundary conditions.\n\nThe signature of the CUDA kernel is __global__ void k_calculateWave2D(float *previousDisplacement_d, float *currentDisplacement_d, float *depth_d, float *previousTmp_d, float *currentTmp_d), where previousDisplacement_d is an array of previous time point states of the displacements, currentDisplacement_d is an array of current time point states of the displacements, depth_d is an array of depth values of each point that affect the speed of waves, previousTmp_d is an array for temporary storage, and currentTmp_d is another array for temporary storage.\n\n>>> k_calculateWave2D({\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.800000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f\n},\n{\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f\n},\n{\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f,\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f,\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f,\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f,\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f,\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f,\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f,\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f,\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f\n}) ->  currentDisplacement_d: {\n    0.000000f, 0.000000f, 0.000000f, 0.000011f, 0.000149f, 0.000835f, 0.000149f, 0.000011f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000009f, 0.000186f, 0.002062f, 0.009411f, 0.002062f, 0.000186f, 0.000009f, 0.000000f, 0.000000f,\n    0.000000f, 0.000009f, 0.000247f, 0.004107f, 0.036926f, 0.129077f, 0.036926f, 0.004107f, 0.000247f, 0.000009f, 0.000000f,\n    0.000011f, 0.000186f, 0.004107f, 0.055204f, 0.376970f, 0.893490f, 0.376969f, 0.055204f, 0.004107f, 0.000186f, 0.000011f,\n    0.000149f, 0.002062f, 0.036926f, 0.376970f, 1.713494f, 1.884681f, 1.713494f, 0.376970f, 0.036926f, 0.002062f, 0.000149f,\n    0.000835f, 0.009411f, 0.129077f, 0.893492f, 1.884684f, -1.106843f, 1.884684f, 0.893492f, 0.129077f, 0.009411f, 0.000835f,\n    0.000149f, 0.002062f, 0.036926f, 0.376976f, 1.713569f, 1.885096f, 1.713569f, 0.376976f, 0.036926f, 0.002062f, 0.000149f,\n    0.000011f, 0.000186f, 0.004116f, 0.055390f, 0.379030f, 0.902888f, 0.379030f, 0.055390f, 0.004116f, 0.000186f, 0.000011f,\n    0.000001f, 0.000019f, 0.000495f, 0.008213f, 0.073852f, 0.258153f, 0.073852f, 0.008213f, 0.000495f, 0.000019f, 0.000001f\n}\n\n>>> k_calculateWave2D({\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f\n},\n{\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f,\n    0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 1.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f, 0.000000f\n},\n{\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f,\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f,\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f,\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f,\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f,\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f,\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f,\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f,\n    1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f, 1.000000f\n}) ->  currentDisplacement_d: {\n    0.000407f, 0.004175f, 0.050254f, 0.284142f, 0.359115f, -0.395784f, 0.359115f, 0.284143f, 0.050254f, 0.004175f, 0.000407f,\n    0.000407f, 0.004175f, 0.050254f, 0.284142f, 0.359115f, -0.395784f, 0.359115f, 0.284143f, 0.050254f, 0.004175f, 0.000407f,\n    0.000407f, 0.004175f, 0.050254f, 0.284142f, 0.359115f, -0.395784f, 0.359115f, 0.284143f, 0.050254f, 0.004175f, 0.000407f,\n    0.000407f, 0.004175f, 0.050254f, 0.284142f, 0.359115f, -0.395784f, 0.359115f, 0.284143f, 0.050254f, 0.004175f, 0.000407f,\n    0.000407f, 0.004175f, 0.050254f, 0.284142f, 0.359115f, -0.395784f, 0.359115f, 0.284143f, 0.050254f, 0.004175f, 0.000407f,\n    0.000407f, 0.004175f, 0.050254f, 0.284142f, 0.359115f, -0.395784f, 0.359115f, 0.284143f, 0.050254f, 0.004175f, 0.000407f,\n    0.000407f, 0.004175f, 0.050254f, 0.284142f, 0.359115f, -0.395784f, 0.359115f, 0.284143f, 0.050254f, 0.004175f, 0.000407f,\n    0.000407f, 0.004175f, 0.050254f, 0.284142f, 0.359115f, -0.395784f, 0.359115f, 0.284143f, 0.050254f, 0.004175f, 0.000407f,\n    0.000407f, 0.004175f, 0.050254f, 0.284142f, 0.359115f, -0.395784f, 0.359115f, 0.284143f, 0.050254f, 0.004175f, 0.000407f\n}\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <assert.h>\n#include <stdio.h>\n#include <cuda.h>\n#include <cuda_runtime.h>\n#include <cooperative_groups.h>\n#include <device_launch_parameters.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/116", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a cuda kernel to find the number of occurrences of a pattern in a sequence where each thread checks for the pattern in the input sequence in parallel and utilizes the Atomic function to aggregate the count value. \n\nThe signature of the function is __global__ void k_patternMatch(char* sequence_d, char* pattern_d, int sequenceLength, int patternLength, int* count_d), where sequence refers to the input string, pattern is the string being searched within sequence, sequenceLength and patternLength represent the lengths of sequence and pattern respectively, and count_d denotes the number of times the pattern appears in the sequence.\n\n>>> k_patternMatch(\"ATCGTGATCGAAGCCT\", \"ATC\", 16, 3, count) -> count: 2\n>>> k_patternMatch(\"ATCGTGATTGAAGCCT\", \"ATCGA\", 16, 5, count) -> count: 0 \n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <limits>\n#include <string>\n#include <cstdio>\n#include <assert.h>\n#include <cuda.h>\n#include <curand_kernel.h>\n#include <cuda_runtime.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/117", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel to perform Sparse Matrix-Vector Multiplication (SpMV) using the Compressed Sparse Row (CSR) format with shared memory optimizations. The kernel should minimize global memory accesses and maximize multiprocessor utilization.\n\nThe k_spmvCsrOptimized kernel should have the signature: __global__ void k_spmvCsrOptimized(float* values, int* colIndices, int* rowPtr, float* x, float* y, int numRows). Here, values contains non-zero elements, colIndices stores column indices, rowPtr marks row boundaries, x is the input vector, y is the output vector, and numRows is the matrix dimension.\n\n>>> k_spmvCsrOptimized(values:{1.0f, 2.0f, 3.0f}, colIndices:{0, 1, 2}, rowPtr:{0, 1, 2, 3}, x:{1.0f, 2.0f, 3.0f}, y, numRows:{3}) -> y:{1.0f, 4.0f, 9.0f}\n>>> k_spmvCsrOptimized(values:{1.0f, 4.0f, 2.0f, 5.0f, 3.0f, 6.0f}, colIndices:{0, 2, 1, 3, 0, 1}, rowPtr:{0, 2, 4, 6, 6}, x:{1.0f, 2.0f, 3.0f, 4.0f}, y, numRows:{4}) -> y:{13.0f, 24.0f, 15.0f, 0.0f}\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cassert>\n#include <cmath>\n#include <cooperative_groups.h>\n#include <cstdio>\n#include <cstdlib>\n#include <cuda_runtime.h>\n#include <iostream>\n#include <vector>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/118", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel to compute the total angular momentum of a system of particles using a warp parallel reduction. Each thread should be responsible for computing the angular momentum contributed by one particle.\n\nThe kernel should have the following signature is __global__ void k_computeAngularMomentum(const float *mass_d, const float3 *pos_d, const float3 *vel_d, float3 *totalAM_d, unsigned int particleCount), where mass_d is an array of particle masses, pos_d is an array of float3 containing particle positions with respect to the origin, vel_d is an array of float3 containing particle velocities, totalAM_d is a pointer to a single float3 in global memory where the total angular momentum (Lx, Ly, Lz) is stored, and particleCount is the total number of particles in the system.\n\n>>> k_computeAngularMomentum(mass_d:{4.370861e+00f, 9.556429e+00f},\n                             pos_d:{{2.319939e+00f, 9.865848e-01f, -3.439814e+00f}, {-3.440055e+00f, -4.419164e+00f, 3.661761e+00f}},\n                             vel_d:{{2.022300e-01f, 4.161452e-01f, -9.588310e-01f}, {9.398197e-01f, 6.648853e-01f, -5.753218e-01f}},\n                             totalAM_d:{0.0f, 0.0f, 0.0f},\n                             particleCount:2) -> totalAM_d: {3.152112e+00, 2.065611e+01, 2.117977e+01}\n\n>>> k_computeAngularMomentum(mass_d:{7.752083e+00f, 2.799273e+00f},\n                             pos_d:{{-1.642612e+00f, -3.415288e+00f, -1.467934e+00f}, {-1.489164e+00f, -3.154448e+00f, -2.816532e-02f}},\n                             vel_d:{{-4.435090e-01f, -6.504617e-01f, 3.839987e-01f}, {-7.099691e-01f, -5.235986e-01f, -7.185734e-01f}},\n                             totalAM_d:{0.0f, 0.0f, 0.0f},\n                             particleCount:2) -> totalAM_d: {-1.126471e+01, 6.997188e+00, -7.545882e+00}\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <stdio.h>\n#include <stdlib.h>\n#include <cassert>\n#include <cuda_runtime.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/119", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel to detect collisions between two polygons using the separating axes theorem method on 2D objects.\n\nThe signature of the kernel is __global__ void k_satCollisionDetectionKernel(const Point* firstShape, int numVertices1, const Point* secondShape, int numVertices2, int* collisionDetected), where firstShape is the pointer to an array of points representing the vertices of the first polygon in device memory, secondShape is the pointer to an array of points representing the vertices of the second polygon in device memory, numVertices1 is the number of vertices in the first polygon, numVertices2 is the number of vertices in the second polygon, and collisionDetected is a pointer to an integer flag in device memory that will be set to 1 if collision detected and 0 otherwise.\n\n>>> k_satCollisionDetectionKernel({{0, 0}, {4, 0}, {4, 4}, {0, 4}}, 4, {{2, 2}, {6, 2}, {6, 6}, {2, 6}}, 4, collisionDetected)-> collisionDetected: 1\n>>> k_satCollisionDetectionKernel({{0, 0}, {4, 0}, {4, 4}, {0, 4}}, 4, {{5, 5}, {9, 5}, {9, 9}, {5, 9}}, 4, collisionDetected)-> collisionDetected: 0 \n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cuda_runtime.h>\n#include <float.h>\n#include <cstdio>\n#include <assert.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/120", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel to count 2D points inside 2D polygons, given as vertex lists, by assigning each polygon to a block and each point to a thread, using warp-level reduction for local count accumulation and atomicAdd for global total.\n\nThe kernel signature is __global__ void k_countPointsInPolygons(const float2* points_d, const int* polyOffsets_d, const float2* polyVertices_d, int* counts_d, int numPoints, int numPolygons), where points_d is the array of points, polyOffsets_d defines the subset vertices in polyVertices_d for the respective polygon, polyVertices is the total vertices set of all polygons, counts_d is the computed result, numPoints is the total number of points, and numPolygons is the total number of polygons in the data set.\n\n>>> k_countPointsInPolygons(points_d:{{2.54f, 3.59f}, {93.56f, 77.84f}},\n                            polyOffsets_d:{0, 3, 6},\n                            polyVertices_d:{{108.63f, 88.34f}, {80.57f, 76.69f}, {-42.25f, 54.29f}, {94.08f, 163.08f}, {52.27f, -4.073f},{111.56f, 72.67f}},\n                            counts_d: {0},\n                            numPoints: 2,\n                            numPolygons: 2) -> counts_d: {0, 1};\n>>> k_countPointsInPolygons(points_d:{{52.75f, 88.66f}, {37.12f, 11.27f}},\n                            polyOffsets_d:{0, 7, 14},\n                            polyVertices_d:{{73.40f, 74.87f}, {63.12f, 73.70f}, {50.87f, 89.70f}, {12.73f, 115.39f}, {24.85f, 75.04f}, {-27.41f, 40.11f}, {-8.50f, 26.75f}, {68.34f, 60.59f}, {-67.15f, 59.18f}, {-29.74f, 36.99f}, {-19.55f, -62.04f}, {-6.79f, -71.06f}, {30.69f, -50.15f}, {110.93f, 7.72f}},\n                            counts_d: {0},\n                            numPoints: 2,\n                            numPolygons: 2) -> counts_d: {0, 1};\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <stdio.h>\n#include <stdlib.h>\n#include <cassert>\n#include <cuda_runtime.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/121", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel to apply a bilateral filter for edge\u2011preserving and smoothing on a 2D image.\n\nThe signature of the function is __global__ void k_bilateralFilterKernel(float *inputImage, float *filteredImage, int widthOfImage, int heightOfImage, int radiusOfFilter, float sigmaOfSpatial, float sigmaOfRange), where inputImage represents the input image pixel data, filteredImage represents the output image where the filtered result is stored, widthOfImage gives the width (number of pixels per row) of the input image, heightOfImage represents the height of the input image, radiusOfFilter represents the radius of the filter window, sigmaOfSpatial the standard deviation for the spatial (distance) weighting in the gaussian function, sigmaOfRange The standard deviation for the range (intensity difference) weighting in the gaussian function.\n\n>>> k_bilateralFilterKernel({4, 4}, filteredImage, 3, 3.0f, 25.0f) -> filteredImage: ({123.260002f, 7.377082f, 95.625015f, 95.624985f, 183.872910f})\n>>> k_bilateralFilterKernel({128, 128}, filteredImage, 5, 4.0f, 30.0f ) -> filteredImage: ({127.500031f, 2.302135f, 126.503929f, 126.503883f, 250.705582f})\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cuda_runtime.h>\n#include <cstdio>\n#include <cmath>\n#include <algorithm>\n#include <assert.h>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/122", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel to perform matrix multiplication by using tensor cores by using mma ptx instruction of dimension m16n8k8 for Ampere Architecture.\nConfigure it in row major by column major format, using bf16 data type for input matrices A (row major) and B (column major), and f32 for accumulator matrix C(row major), all input\nmatrices will have m16n8k8 compatible dimensions.\n\nThe signature of the function is __global__ void k_mmaTensorMatMul(__nv_bfloat16 *inputLayerA_d, __nv_bfloat16 *inputLayerB_d, float *outputLayer_d, int mDim, int nDim, int kDim), where inputLayerA_d is first input layer matrix with dimension mDim x kDim, inputLayerB_d is second input layer matrix with dimension kDim x nDim, outputLayer_d is output matrix with dimension mDim x nDim.\n\n>>> k_mmaTensorMatMul({3, 6, 7, 5}, {3, 5}, outputLayer_d, 2, 1, 2)-> outputLayer_d: ({44, 43})\n>>> k_mmaTensorMatMul({3, 6, 17, 15}, {13, 15}, outputLayer_d, 2, 1, 2)-> outputLayer_d: ({294, 303})\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cstdio>\n#include <cassert>\n#include <cstdint>\n#include <random>\n#include <cuda_runtime.h>\n#include <mma.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/123", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel to simulate a logic circuit such as a MIMD (multiple instruction multiple data) pipeline, using shared-memory lookup table to accelerate the redundant lookups. Use circuit selection codes for each stage in the instruction code and compute the circuit output by a single lookup for each stage the data goes through.\n\nSignature of the CUDA kernel is __global__ void k_simulateLogicCircuit(uint32_t* input_d, uint8_t* output_d, uint8_t* lookupTable_d), where input_d is pointer to input array with each element representing 24 bit instruction and 8bit data, output_d is pointer to output array of 8 bit results of simulated logic circuit, and lookupTable_d is pointer to the truth table of all circuits used in the simulated MIMD pipeline.\n\n>>> k_simulateLogicCircuit({\n    256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270\n}, output_d,{\n    0, 0, 0, 0, 0, 1, 2, 3, 0, 2, 4, 6, 0, 3, 6, 9, \n    0, 4, 8, 12, 0, 5, 10, 15, 0, 6, 12, 18, 0, 7, 14, 21\n}) -> output_d: {\n    0, 0, 0, 0, 0, 1, 2, 3, 0, 2, 4, 6, 0, 3, 6\n}\n\n>>> k_simulateLogicCircuit({\n    256, 257, 258, 259, 260, 261, 262, 263, 256, 257, 258, 259, 260, 261, 262\n}, output_d,{\n    0, 1, 1, 2, 2, 3, 3, 4\n}) -> output_d: {\n    0, 1, 1, 2, 2, 3, 3, 4, 0, 1, 1, 2, 2, 3, 3\n}\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <assert.h>\n#include <cstdio>\n#include <cstdint>\n#include <cuda.h>\n#include <cuda_runtime.h>\n#include <device_launch_parameters.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/124", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a cuda kernel to sort integers using parallel bubble sort algorithm. This algorithm sorts the integers in N iterations, where N is the size of the input array. In each iteration the adjacent pairs of integers across the array are compared in two steps, in first step pairs with even index are compared and in second step pairs with odd index are compared. \n\nThe signature of the function is __global__ void k_bubbleSort(int *inputOutput_d, int numElements), where inputOutput_d is a pointer to an array of unsorted integers that are sorted inplace, numElements denotes the number of integers in the input. \n\n>>> k_bubbleSort({9, 3, 4, 6, 2, 5}, 6) -> inputOutput_d: ({2, 3, 4, 5, 6, 9})\n>>> k_bubbleSort({19, 17, 13, 18, 21, 24}, 6) -> inputOutput_d: ({13, 17, 18, 19, 21, 24})\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cstdio>\n#include <limits.h>\n#include <assert.h>\n#include <cuda_runtime.h>\n#include <cooperative_groups.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/125", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel to detect presence of a signal using energy detection algorithm. Given an input signal vector $a$ with $n$ elements and an energy window of length $m$ ($m < $n). The kernel should use warp shuffles, reductions and atomics to determine the index corresponding to the peak output.\n\nThe signature of the function is __global__ void k_calculateMovingEnergy(int *inputVector, int windowLength, int *maxResult, int *maxResultIdx, int size), where inputVector is the input signal array, windowLength is the length of the window to calculate energy, maxResult is the peak energy window output, maxResultIdx contains index of peak energy and size is the length of the input signal array.\n\n>>> k_calculateMovingEnergy({1, 2, 3, 4, 5, 6, 7}, 2, maxResult, maxResultIdx, 7) -> maxResult : 85, maxResultIdx : 5\n>>> k_calculateMovingEnergy({3, 4, 2, 7, 9, 8, 1}, 3, maxResult, maxResultIdx, 7) -> maxResult : 194, maxResultIdx : 3\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cstdio>\n#include <algorithm>\n#include <cuda_runtime.h>\n#include <assert.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/126", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nThis CUDA kernel computes the Histogram of Oriented Gradients (HOG) for images using signed gradients (0\u00b0 to 180\u00b0) and 20\u00b0 bins (9 bins total). Each thread processes a single pixel, computes gradients via the Sobel operator, and updates a block-level shared memory histogram, which is then stored in global memory.\n\nThe signature of the function is __global__ void k_computeHOG(unsigned char *image, int *hogDescriptor, int width, int height), where the image is the input grayscale image stored in a 1D array, hogDescriptor is the output histogram array (9-bin histogram per block),\nwidth and height are image dimensions.\n\n>>> k_computeHOG({50,55,60,65,70,75,80,85,90,95,100,105,110,115,120,125,130,135,140,145,150,155,160,165,170,175,180,185,190,195,200,205,210,215,220,225,230,235,240,245,250,255,245,235,225,215,205,195,185,175,\n165,155,145,135,125,115,105,95,85,75,65,55,45,35}, hogDescriptor, 8, 8)->hogDescriptor:{0, 16, 0, 304, 672, 32, 0, 0, 0}\n>>> k_computeHOG({200,180,160,140,40,20,200,180,80,60,40,20,120,100,80,60,160,140,120,100,200,180,160,140,40,20,200,180,80,60,40,20}, hogDescriptor, 4, 8)->hogDescriptor:{0, 0, 0, 64, 128, 224, 32, 64, 0}\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <cstdio>\n#include <cfloat>\n#include <algorithm>\n#include <cuda_runtime.h>\n#include <assert.h>\n#include <iostream>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
{"task_id": "CUDA/127", "question": [{"role": "system", "content": "You are a CUDA programming expert capable of generating high-quality, efficient CUDA code with best practices, optimized for performance and clarity."}, {"role": "user", "content": "You will be given an instruction, and you should complete the code. Note that:\n- Think carefully before providing your final answer.\n- Implement the body of the function(s). Do not include any additional code outside the function(s).\n- Wrap the completed function code, including the provided signatures, inside a single ```cuda markdown code block.\n- Make sure to use the precise function signature in your response if it's provided in the query.\n\nNow you are given the below instruction:\n\nWrite a CUDA kernel to find the maximum value in a large integer array using parallel reduction with warp shuffle operations and shared memory optimizations.\n\nThe signature of the kernel is __global__ void k_findMax(int* input_d, int* result_d, size_t numElements, int warpsPerBlock, int warpSize), where input_d is a device pointer to the input array of 32-bit integers, result_d is a single-element device pointer to store the maximum value, numElements is the total number of elements in the input array, warpsPerBlock is the number of warps per block (calculated from device properties) and warpSize is the Size of the warp (calculated from device properties)\n\nThe implementation must use __shfl_down_sync for warp-level reduction, utilize shared memory for block-level aggregation, implement grid-stride loops for scalable input handling, use atomicMax for final global maximum update, and handle arbitrary input sizes including non-multiples of block size.\n\n>>> k_findMax({1, 2, 3, 98765}, result_d, 4,  warpsPerBlock, warpSize) -> 98765\n>>> k_findMax({-5, -3, 0, -10, -8}, result_d, 5,   warpsPerBlock, warpSize) -> 0\n\n\nPlease respond with thinking process and your final answer.\n\nThe following headers are already defined and should not be included in the answer:\n```cuda\n#include <assert.h>\n#include <limits>\n#include <cstdio>\n#include <limits>\n#include <vector>\n#include <cuda_runtime.h>\n```\nPlease do not include any additional headers in your answer.\n"}], "data_source": "compute-eval"}
